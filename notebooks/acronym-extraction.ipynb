{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype acronym extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "\n",
    "# import snorkel and gwasdb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'\n",
    "\n",
    "# set up matplotlib\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLDocParser\n",
    "from extractor.parser import UnicodeXMLTableDocParser\n",
    "\n",
    "xml_parser = UnicodeXMLTableDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 35s, sys: 12.7 s, total: 3min 48s\n",
      "Wall time: 5min 35s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser, OmniParser\n",
    "import cPickle\n",
    "\n",
    "table_parser = OmniParser()\n",
    "\n",
    "corpus_name = 'gwas-table-corpus.pkl'\n",
    "try:\n",
    "    with open(corpus_name,\"r\") as pkl:\n",
    "        corpus = cPickle.load(pkl)\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser, max_docs=100)\n",
    "    %time corpus = cp.parse_corpus(name='GWAS Corpus')\n",
    "    # pickling currently doesn't work...\n",
    "#     with open(corpus_name,\"w\") as pkl:\n",
    "#         corpus = cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### From tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import DictionaryMatch, Union, CellNameMatcher, CellDictNameMatcher\n",
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams, CellSpace\n",
    "\n",
    "# Define a candidate space\n",
    "cells = CellSpace()\n",
    "\n",
    "# Create a list of possible words that could denote phenotypes\n",
    "acro_words = ['abbreviation', 'acronym', 'phenotype']\n",
    "phen_words = ['trait', 'phenotype', 'description']\n",
    "\n",
    "# Define matchers\n",
    "phen_matcher = CellDictNameMatcher(axis='col', d=phen_words, n_max=3, ignore_case=True)\n",
    "acro_matcher = CellDictNameMatcher(axis='col', d=acro_words, n_max=3, ignore_case=True)\n",
    "\n",
    "phen_extractor = EntityExtractor(cells, phen_matcher)\n",
    "acro_extractor = EntityExtractor(cells, acro_matcher)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import AlignedTableRelationExtractor\n",
    "relation_extractor = AlignedTableRelationExtractor(acro_extractor, phen_extractor, axis='row', induced=True)\n",
    "tables = corpus.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 59s, sys: 1.39 s, total: 2min 1s\n",
      "Wall time: 2min 1s\n",
      "96 relations extracted, e.g.\n",
      "SpanPair(Span(\"CD40L\", context=None, chars=[0,4], words=[0,0]), Span(\"CD40 Ligand, serum & plasma\", context=None, chars=[0,26], words=[0,5]))\n",
      "SpanPair(Span(\"CD40L\", context=None, chars=[0,4], words=[0,0]), Span(\"2\", context=None, chars=[0,0], words=[0,0]))\n",
      "SpanPair(Span(\"CRP\", context=None, chars=[0,2], words=[0,0]), Span(\"C-reactive protein\", context=None, chars=[0,17], words=[0,1]))\n",
      "SpanPair(Span(\"CRP\", context=None, chars=[0,2], words=[0,0]), Span(\"5\", context=None, chars=[0,0], words=[0,0]))\n",
      "SpanPair(Span(\"ICAM1\", context=None, chars=[0,4], words=[0,0]), Span(\"Intercellular adhesion molecule-1\", context=None, chars=[0,32], words=[0,2]))\n"
     ]
    }
   ],
   "source": [
    "%time candidates = relation_extractor.extract(tables, name='all')\n",
    "table_c = candidates\n",
    "print \"%s relations extracted, e.g.\" % len(table_c)\n",
    "for cand in table_c[:5]: \n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.19 s, sys: 73.1 ms, total: 1.26 s\n",
      "Wall time: 7.66 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import SentenceParser, CorpusParser\n",
    "from extractor.parser import UnicodeXMLDocParser, GWASXMLDocParser\n",
    "\n",
    "xml_parser = GWASXMLDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    title='.//front//article-title//text()',\n",
    "    abstract='.//abstract//p//text()',\n",
    "    n_par=5,\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)\n",
    "\n",
    "sent_parser = SentenceParser()\n",
    "cp = CorpusParser(xml_parser, sent_parser, max_docs=15)\n",
    "%time text_corpus = cp.parse_corpus(name='GWAS Text Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CellSpace, TableNgrams\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "from snorkel.candidates import EntityExtractor, RelationExtractor, UnionExtractor\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams8 = Ngrams(n_max=8)\n",
    "ngrams3 = Ngrams(n_max=3)\n",
    "cells = CellSpace()\n",
    "table_ngrams3 = TableNgrams(n_max=3)\n",
    "\n",
    "# Define matchers\n",
    "phen_matcher = RegexMatchSpan(rgx=r'.+ \\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "acro_matcher = RegexMatchSpan(rgx=r'\\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "\n",
    "# Extractors\n",
    "phen_txt_ngram_extractor = EntityExtractor(ngrams8, phen_matcher)\n",
    "phen_txt_cells_extractor = EntityExtractor(cells, phen_matcher)\n",
    "acro_txt_ngram_extractor = EntityExtractor(ngrams3, acro_matcher)\n",
    "acro_txt_cells_extractor = EntityExtractor(table_ngrams3, acro_matcher)\n",
    "\n",
    "# Filtering functions\n",
    "def overlap_filter_fn(span0, span1):\n",
    "    if hasattr(span0.context, 'cell') and hasattr(span1.context, 'cell'):\n",
    "        if span0.context.cell != span1.context.cell: return False\n",
    "    if len(span1.get_span().split()) >= 15: return False\n",
    "    start0, end0 = span0.char_start, span0.char_end\n",
    "    start1, end1 = span1.char_start, span1.char_end\n",
    "    return True if start1 <= start0 <= end0 <= end1 else False\n",
    "\n",
    "# Relation extractor\n",
    "txt_tab_ngram_extractor = RelationExtractor(acro_txt_ngram_extractor, phen_txt_ngram_extractor, filter_fn=overlap_filter_fn)\n",
    "txt_tab_cells_extractor = RelationExtractor(acro_txt_cells_extractor, phen_txt_cells_extractor, filter_fn=overlap_filter_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acroynms from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.6 s, sys: 2.73 s, total: 53.3 s\n",
      "Wall time: 1min 9s\n",
      "19795 candidates extracted from text in tables\n"
     ]
    }
   ],
   "source": [
    "%time txt_tab_c = txt_tab_ngram_extractor.extract(corpus.get_phrases(), name='all')\n",
    "print len(txt_tab_c), 'candidates extracted from text in tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acronyms from full table cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1.72 ms, sys: 432 Âµs, total: 2.15 ms\n",
      "Wall time: 2.3 ms\n",
      "0 candidates extracted from text in full table cells\n"
     ]
    }
   ],
   "source": [
    "%time txt_cel_c = txt_tab_cells_extractor.extract(corpus.get_tables(), name='all')\n",
    "print len(txt_cel_c), 'candidates extracted from text in full table cells'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acroynms from abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.28 s, sys: 39.3 ms, total: 2.32 s\n",
      "Wall time: 2.34 s\n",
      "884 candidates extracted from text in abstracts\n"
     ]
    }
   ],
   "source": [
    "%time txt_txt_c = txt_tab_ngram_extractor.extract(text_corpus.get_sentences(), name='all')\n",
    "print len(txt_txt_c), 'candidates extracted from text in abstracts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning the correctness of relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1288\n"
     ]
    }
   ],
   "source": [
    "from snorkel.candidates import UnionExtractor\n",
    "\n",
    "contexts = [corpus.get_tables(), corpus.get_phrases(), text_corpus.get_sentences()]\n",
    "extractors = [txt_tab_cells_extractor, txt_tab_ngram_extractor, txt_tab_ngram_extractor]\n",
    "joint_extractor = UnionExtractor(extractor_list=extractors, context_list=contexts)\n",
    "all_c = joint_extractor.union()\n",
    "print len(all_c)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a gold set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a gold set, we save all extracted relations into a csv file. We annotate it manually, and save the result to a second file. It contains pairs of phenotype and rsid strings; if that file exists, we take these as gold truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "GEE p-val (Rank)â â \n",
      "GEE p-val (Rank)\n",
      "('17903294', u'GEE p-val (Rank)', u'(Rank)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "GEE Pval (Rank)â â \n",
      "GEE Pval (Rank)\n",
      "('17903294', u'GEE Pval (Rank)', u'(Rank)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Total Cerebral Brain Volume (ATCBV)\n",
      "Total Cerebral Brain Volume (ATCBV)\n",
      "('17903297', u'Total Cerebral Brain Volume (ATCBV)', u'(ATCBV)') 1\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Factor 1:Verbal Memory (F1)\n",
      "('17903297', u'Factor 1:Verbal Memory (F1)', u'(F1)') 1\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Factor 1:Verbal Memory (F1)\n",
      "('17903297', u'Factor 1:Verbal Memory (F1)', u'(F1)') 1\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "('17903297', u'Factor 2:Visual Memory and Organization (F2)', u'(F2)') 1\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "('17903297', u'Factor 2:Visual Memory and Organization (F2)', u'(F2)') 1\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "('17903297', u'Factor 3: Measure of attention and executive function-Trails A and B (F3)', u'(F3)') 1\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "('17903297', u'Factor 3: Measure of attention and executive function-Trails A and B (F3)', u'(F3)') 1\n",
      "\n",
      "28 yr time averaged FPG (tFPG)\n",
      "28 yr time averaged FPG (tFPG)\n",
      "('17903298', u'28 yr time averaged FPG (tFPG)', u'(tFPG)') 1\n",
      "\n",
      "Stage 2 Exercise systolic blood pressure (SBP)\n",
      "Stage 2 Exercise systolic blood pressure (SBP)\n",
      "('17903301', u'Stage 2 Exercise systolic blood pressure (SBP)', u'(SBP)') 1\n",
      "\n",
      "Stage 2 Exercise systolic blood pressure (SBP)\n",
      "Stage 2 Exercise systolic blood pressure (SBP)\n",
      "('17903301', u'Stage 2 Exercise systolic blood pressure (SBP)', u'(SBP)') 1\n",
      "\n",
      "Stage 2 Exercise diastolic blood pressure (DBP)\n",
      "Stage 2 Exercise diastolic blood pressure (DBP)\n",
      "('17903301', u'Stage 2 Exercise diastolic blood pressure (DBP)', u'(DBP)') 1\n",
      "\n",
      "Stage 2 Exercise diastolic blood pressure (DBP)\n",
      "Stage 2 Exercise diastolic blood pressure (DBP)\n",
      "('17903301', u'Stage 2 Exercise diastolic blood pressure (DBP)', u'(DBP)') 1\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "(GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'(GFR), UAELNMV6 (UAE)', u'(GFR)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "(GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'(GFR), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "CysC), and TSHMEAN34MV (TSH)\n",
      "('17903292', u'CysC), and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'GFR), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "), and TSHMEAN34MV (TSH)\n",
      "('17903292', u'), and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "), UAELNMV6 (UAE)\n",
      "('17903292', u'), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2a.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p value of the GEE test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", UAELNMV6 (UAE)\n",
      "('17903292', u', UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "(GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'(GFR), UAELNMV6 (UAE)', u'(GFR)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "(GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'(GFR), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "CysC), and TSHMEAN34MV (TSH)\n",
      "('17903292', u'CysC), and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "GFR), UAELNMV6 (UAE)\n",
      "('17903292', u'GFR), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "), and TSHMEAN34MV (TSH)\n",
      "('17903292', u'), and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      "), UAELNMV6 (UAE)\n",
      "('17903292', u'), UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", and TSHMEAN34MV (TSH)\n",
      "('17903292', u', and TSHMEAN34MV (TSH)', u'(TSH)') 0\n",
      "\n",
      "2b.Top 25 SNPs for association with GFR (examination 7), UAE (examination 6), cysC (examination 7), and mean TSH (examinations 3 and 4) based on the lowest p-value of the FBAT test. Corresponding phenotype names on the web are GFRMV7 (GFR), UAELNMV6 (UAE), CYSCMV7 (CysC), and TSHMEAN34MV (TSH)\n",
      ", UAELNMV6 (UAE)\n",
      "('17903292', u', UAELNMV6 (UAE)', u'(UAE)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "GEE p-val (Rank)â â \n",
      "GEE p-val (Rank)\n",
      "('17903294', u'GEE p-val (Rank)', u'(Rank)') 0\n",
      "\n",
      "GEE p-val (Rank)â â \n",
      "p-val (Rank)\n",
      "('17903294', u'p-val (Rank)', u'(Rank)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "GEE Pval (Rank)â â \n",
      "GEE Pval (Rank)\n",
      "('17903294', u'GEE Pval (Rank)', u'(Rank)') 0\n",
      "\n",
      "GEE Pval (Rank)â â \n",
      "Pval (Rank)\n",
      "('17903294', u'Pval (Rank)', u'(Rank)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Physical Position (bp)\n",
      "('17903294', u'Physical Position (bp)', u'(bp)') 0\n",
      "\n",
      "Physical Position (bp)â \n",
      "Position (bp)\n",
      "('17903294', u'Position (bp)', u'(bp)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Factor 1:Verbal Memory (F1)\n",
      "('17903297', u'Factor 1:Verbal Memory (F1)', u'(F1)') 1\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      ":Verbal Memory (F1)\n",
      "('17903297', u':Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      ":Verbal Memory (F1)\n",
      "('17903297', u':Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "1:Verbal Memory (F1)\n",
      "('17903297', u'1:Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Verbal Memory (F1)\n",
      "('17903297', u'Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Verbal Memory (F1)\n",
      "('17903297', u'Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      ":Verbal Memory (F1)\n",
      "('17903297', u':Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Memory (F1)\n",
      "('17903297', u'Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Memory (F1)\n",
      "('17903297', u'Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Verbal Memory (F1)\n",
      "('17903297', u'Verbal Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 1:Verbal Memory (F1)\n",
      "Memory (F1)\n",
      "('17903297', u'Memory (F1)', u'(F1)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      ":Visual Memory and Organization (F2)\n",
      "('17903297', u':Visual Memory and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Memory and Organization (F2)\n",
      "('17903297', u'Memory and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Memory and Organization (F2)\n",
      "('17903297', u'Memory and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Visual Memory and Organization (F2)\n",
      "('17903297', u'Visual Memory and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "and Organization (F2)\n",
      "('17903297', u'and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "and Organization (F2)\n",
      "('17903297', u'and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Memory and Organization (F2)\n",
      "('17903297', u'Memory and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Organization (F2)\n",
      "('17903297', u'Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Organization (F2)\n",
      "('17903297', u'Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "and Organization (F2)\n",
      "('17903297', u'and Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 2:Visual Memory and Organization (F2)\n",
      "Organization (F2)\n",
      "('17903297', u'Organization (F2)', u'(F2)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "executive function-Trails A and B (F3)\n",
      "('17903297', u'executive function-Trails A and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "A and B (F3)\n",
      "('17903297', u'A and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "A and B (F3)\n",
      "('17903297', u'A and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "function-Trails A and B (F3)\n",
      "('17903297', u'function-Trails A and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "and B (F3)\n",
      "('17903297', u'and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "and B (F3)\n",
      "('17903297', u'and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "A and B (F3)\n",
      "('17903297', u'A and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "B (F3)\n",
      "('17903297', u'B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "B (F3)\n",
      "('17903297', u'B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "and B (F3)\n",
      "('17903297', u'and B (F3)', u'(F3)') 0\n",
      "\n",
      "Factor 3: Measure of attention and executive function-Trails A and B (F3)\n",
      "B (F3)\n",
      "('17903297', u'B (F3)', u'(F3)') 0\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# store relations to annotate\n",
    "with open('acronyms.unannotated.tsv', 'w') as f:\n",
    "    for span_pair in all_c:\n",
    "        doc_id = span_pair.span0.context.document.name\n",
    "        str1 = span_pair.span0.get_span()\n",
    "        str2 = span_pair.span1.get_span()\n",
    "        if (doc_id, str1, str2) not in K: \n",
    "            if hasattr(span_pair.span1.context, 'cell'):\n",
    "                print span_pair.span0.context.cell.text\n",
    "                print span_pair.span0.get_span()\n",
    "                print (doc_id, str1, str2), LF_full_cell(span_pair)\n",
    "                print \n",
    "        try:\n",
    "            f.write('%s\\t%s\\t%s\\n' % (doc_id, str2, str1))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "We now load the results of our annotation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = dict()\n",
    "with open('acronyms.anotated.txt') as f:\n",
    "    text = f.read()\n",
    "    for line in text.split('\\r'):\n",
    "        doc_id, str1, str2, res = line.strip().split('\\t')\n",
    "        res = 1 if int(res) == 1 else -1\n",
    "        annotations[(doc_id, str2, str1)] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying table acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature index...\n",
      "Extracting features...\n"
     ]
    }
   ],
   "source": [
    "from snorkel.features import TableNgramPairFeaturizer\n",
    "\n",
    "pkl_f = 'acro_table_feats.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        featurizer = cPickle.load(f)\n",
    "except:\n",
    "    featurizer = TableNgramPairFeaturizer()\n",
    "    featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 0\n",
      "Gold set size: 0\n",
      "Positive labels in training set: 0\n",
      "Negative labels in training set: 0\n",
      "Positive labels in gold set: 0\n",
      "Negative labels in gold set: 0\n"
     ]
    }
   ],
   "source": [
    "def spair2uid(span_pair):\n",
    "    doc_id = span_pair.span0.context.document.name\n",
    "    str1 = span_pair.span0.get_span()\n",
    "    str2 = span_pair.span1.get_span()\n",
    "    return (doc_id, str1, str2)\n",
    "\n",
    "# Split into train and test set\n",
    "training_candidates = []\n",
    "gold_candidates     = []\n",
    "gold_labels         = []\n",
    "n_half = len(candidates)/2\n",
    "for c in candidates[:n_half]:\n",
    "    uid = spair2uid(c)\n",
    "    if uid in annotations:\n",
    "        gold_candidates.append(c)\n",
    "        gold_labels.append(annotations[uid])\n",
    "    else:\n",
    "        training_candidates.append(c)\n",
    "training_candidates.extend(candidates[n_half:])\n",
    "gold_labels = np.array(gold_labels)\n",
    "print \"Training set size: %s\" % len(training_candidates)\n",
    "print \"Gold set size: %s\" % len(gold_candidates)\n",
    "print \"Positive labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==1])\n",
    "print \"Negative labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==-1])\n",
    "print \"Positive labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==1])\n",
    "print \"Negative labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF1_digits(m):\n",
    "    txt = m.span1.get_span()\n",
    "    frac_num = len([ch for ch in txt if ch.isdigit()]) / float(len(txt))\n",
    "    return -1 if frac_num > 0.5 else +1\n",
    "def LF1_short(m):\n",
    "    txt = m.span1.get_span()\n",
    "    return -1 if len(txt) < 5 else 0\n",
    "\n",
    "LF_tables = [LF1_digits, LF1_short]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LFs...\n",
      "Featurizing...\n",
      "Building feature index...\n",
      "Extracting features...\n",
      "============================================================\n",
      "LF Summary Statistics: 2 LFs applied to 0 candidates\n",
      "------------------------------------------------------------\n",
      "Coverage (candidates w/ > 0 labels):\t\tnan%\n",
      "Overlap (candidates w/ > 1 labels):\t\tnan%\n",
      "Conflict (candidates w/ conflicting labels):\tnan%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from snorkel.snorkel import TrainingSet\n",
    "from snorkel.features import NgramFeaturizer\n",
    "\n",
    "training_set = TrainingSet(training_candidates, LF_tables, featurizer=TableNgramPairFeaturizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "zero-size array to reduction operation minimum which has no identity",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-225-f63955196e56>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlf_stats\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtraining_set\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlf_stats\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mlf_stats\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m5\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mlf_stats\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"coverage\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/Library/Python/2.7/site-packages/pandas/tools/plotting.pyc\u001b[0m in \u001b[0;36mhist_frame\u001b[0;34m(data, column, by, grid, xlabelsize, xrot, ylabelsize, yrot, ax, sharex, sharey, figsize, layout, **kwds)\u001b[0m\n\u001b[1;32m   2073\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mxaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2074\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0myaxis\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_visible\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2075\u001b[0;31m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdropna\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2076\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_title\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcol\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2077\u001b[0m         \u001b[0max\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgrid\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/matplotlib/axes.pyc\u001b[0m in \u001b[0;36mhist\u001b[0;34m(self, x, bins, range, normed, weights, cumulative, bottom, histtype, align, orientation, rwidth, log, color, label, stacked, **kwargs)\u001b[0m\n\u001b[1;32m   8310\u001b[0m             \u001b[0mxmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8311\u001b[0m             \u001b[0;32mfor\u001b[0m \u001b[0mxi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 8312\u001b[0;31m                 \u001b[0mxmin\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   8313\u001b[0m                 \u001b[0mxmax\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mxmax\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmax\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   8314\u001b[0m             \u001b[0mbin_range\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mxmin\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mxmax\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/Library/Python/2.7/site-packages/numpy/core/_methods.pyc\u001b[0m in \u001b[0;36m_amin\u001b[0;34m(a, axis, out, keepdims)\u001b[0m\n\u001b[1;32m     27\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_amin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 29\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mumr_minimum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_sum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0ma\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkeepdims\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: zero-size array to reduction operation minimum which has no identity"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAsUAAAEACAYAAABbBguCAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nAAAAAAAAAAAAsL//B8S+LX821uDQAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x110dfb4d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lf_stats = training_set.lf_stats()\n",
    "lf_stats[:5]\n",
    "lf_stats.hist(\"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import Learner\n",
    "import snorkel.learning\n",
    "from snorkel.learning import LogReg\n",
    "\n",
    "learner = Learner(training_set, model=LogReg())\n",
    "\n",
    "# Splitting into CV and test set\n",
    "n_half = len(gold_candidates)/2\n",
    "test_candidates = gold_candidates[:n_half]\n",
    "test_labels     = gold_labels[:n_half]\n",
    "cv_candidates   = gold_candidates[n_half:]\n",
    "cv_labels       = gold_labels[n_half:]\n",
    "\n",
    "from snorkel.learning_utils import GridSearch\n",
    "gs       = GridSearch(learner, ['mu', 'lf_w0'], [[1e-5, 1e-7],[1.0,2.0]])\n",
    "gs_stats = gs.fit(cv_candidates, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner.test_wmv(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = learner.predict_wmv(candidates)\n",
    "resolved_acronyms = [spair2uid(c) for (c, p) in zip(candidates, preds) if p == 1]\n",
    "print resolved_acronyms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# mislabeled_cand = learner.mislabeled_test_candidates(test_candidates, test_labels)\n",
    "# for (c,p,g) in mislabeled_cand[:10]:\n",
    "#     print c.span0.context.document.name\n",
    "#     print c.span0.context    \n",
    "#     print c.span1.context\n",
    "#     print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classifying sentence acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import UnionExtractor\n",
    "contexts = [corpus.get_tables(), corpus.get_phrases(), text_corpus.get_sentences()]\n",
    "extractors = [txt_tab_cells_extractor, txt_tab_ngram_extractor, txt_tab_ngram_extractor]\n",
    "joint_extractor = UnionExtractor(extractor_list=extractors, context_list=contexts)\n",
    "\n",
    "text_c = joint_extractor.union()\n",
    "print len(text_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for c in text_c:\n",
    "    if c.span0.context.document.name == '17903294':\n",
    "        print unicode(c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# helpers\n",
    "def spairtxt2uid(span_pair):\n",
    "    doc_id = span_pair.span0.context.document.name\n",
    "    str1 = span_pair.span1.get_span()\n",
    "    str2 = span_pair.span0.get_span()\n",
    "    acro = str2[1:-1]\n",
    "    phen = str1.split(' (')[0]\n",
    "    return (doc_id, acro, phen)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We really trust the first stage, so if an acronym has been resolved there, remove it from this stage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_text_c = list()\n",
    "resolved = {(doc_id, acro) for doc_id, _, acro in resolved_acronyms}\n",
    "for c in text_c:\n",
    "    doc_id, phen, acro = spairtxt2uid(c)\n",
    "#     print doc_id, phen, acro\n",
    "    if (doc_id, acro) not in resolved:\n",
    "        new_text_c.append(c)\n",
    "\n",
    "print len(text_c), len(new_text_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.features import NgramPairFeaturizer\n",
    "\n",
    "pkl_f = 'acro_text_feats.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        featurizer = cPickle.load(f)\n",
    "except:\n",
    "    featurizer = NgramPairFeaturizer()\n",
    "    featurizer.fit_transform(text_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "training_candidates = []\n",
    "gold_candidates     = []\n",
    "gold_labels         = []\n",
    "n_half = len(text_c)/2\n",
    "for c in text_c[:n_half]:\n",
    "    uid = spair2uid(c)\n",
    "    if uid in annotations:\n",
    "        gold_candidates.append(c)\n",
    "        gold_labels.append(annotations[uid])\n",
    "    else:\n",
    "        training_candidates.append(c)\n",
    "training_candidates.extend(text_c[n_half:])\n",
    "gold_labels = np.array(gold_labels)\n",
    "print \"Training set size: %s\" % len(training_candidates)\n",
    "print \"Gold set size: %s\" % len(gold_candidates)\n",
    "print \"Positive labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==1])\n",
    "print \"Negative labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==-1])\n",
    "print \"Positive labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==1])\n",
    "print \"Negative labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "# positive LFs\n",
    "def LF_acro_matches(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    words = phen.strip().split()\n",
    "    if len(acro) == len(words):\n",
    "        w_acro = ''.join([w[0] for w in words])\n",
    "        if w_acro.lower() == acro.lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_matches_with_dashes(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    words = re.split(' |-', phen)\n",
    "    if len(acro) == len(words):\n",
    "        w_acro = ''.join([w[0] for w in words])\n",
    "        if w_acro.lower() == acro.lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_first_letter(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    if not any(l.islower() for l in phen): return 0\n",
    "    words = phen.strip().split()\n",
    "    if len(acro) <= len(words):\n",
    "        if words[0].lower() == acro[0].lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_prefix(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    phen = phen.replace('-', '')\n",
    "    if phen[:2].lower() == acro[:2].lower():\n",
    "        return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_matches_last_letters(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    words = phen.strip().split()\n",
    "    prev_words = m.span1.pre_window(d=1) + words\n",
    "    w_prev_acro = ''.join([w[0] for w in prev_words])\n",
    "    if w_prev_acro.lower() == acro.lower(): return 0\n",
    "    for r in (1,2):\n",
    "        new_acro = acro[r:]\n",
    "        if len(new_acro) < 3: continue\n",
    "        if len(new_acro) == len(words):\n",
    "            w_acro = ''.join([w[0] for w in words])\n",
    "            if w_acro.lower() == new_acro.lower():\n",
    "                return +1\n",
    "    return 0\n",
    "\n",
    "def LF_full_cell(m):\n",
    "    \"\"\"If only phrase in cell is A B C (XYZ), then it's correct\"\"\"\n",
    "    if not hasattr(m.span1.context, 'cell'): return 0\n",
    "    return 1 if m.span1.context.cell.text == m.span1.get_span() else 0\n",
    "\n",
    "def LF_start(m):\n",
    "    punc = ',.;!?()\\'\"'\n",
    "    if m.span1.get_word_start() == 0 or any(c in punc for c in m.span1.pre_window(d=1)):\n",
    "        _, acro, phen = spairtxt2uid(m)\n",
    "        if phen[0].lower() == acro[0].lower(): \n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "LF_txt_pos = [LF_acro_matches, LF_acro_matches_with_dashes, LF_acro_first_letter, LF_acro_prefix, LF_acro_matches_last_letters, LF_full_cell, LF_start]\n",
    "\n",
    "# negative LFs\n",
    "def LF_no_pos(m):\n",
    "    return -1 if not any(LF(m) for LF in LF_txt_pos) else 0\n",
    "\n",
    "def LF_short(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    return -1 if len(acro) == 1 else 0\n",
    "\n",
    "def LF_lc(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    return -1 if all(l.islower() for l in acro) else 0\n",
    "\n",
    "def LF_uc(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    return -2 if not any(l.islower() for l in phen) else 0\n",
    "\n",
    "def LF_punc(m):\n",
    "    _, acro, phen = spairtxt2uid(m)\n",
    "    punc = ',.;!?()'\n",
    "    return -1 if any(c in punc for c in phen) else 0\n",
    "    \n",
    "\n",
    "LF_txt_neg = [LF_no_pos, LF_short, LF_lc, LF_uc, LF_punc]\n",
    "\n",
    "LF_txt = LF_txt_pos + LF_txt_neg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import TrainingSet\n",
    "from snorkel.features import NgramFeaturizer\n",
    "\n",
    "training_set = TrainingSet(training_candidates, LF_txt, featurizer=NgramPairFeaturizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lf_stats = training_set.lf_stats()\n",
    "lf_stats[:5]\n",
    "lf_stats.hist(\"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import Learner\n",
    "import snorkel.learning\n",
    "from snorkel.learning import LogReg\n",
    "\n",
    "text_learner = Learner(training_set, model=LogReg())\n",
    "\n",
    "# Splitting into CV and test set\n",
    "n_half = len(gold_candidates)/2\n",
    "test_candidates = gold_candidates[:n_half]\n",
    "test_labels     = gold_labels[:n_half]\n",
    "cv_candidates   = gold_candidates[n_half:]\n",
    "cv_labels       = gold_labels[n_half:]\n",
    "\n",
    "from snorkel.learning_utils import GridSearch\n",
    "gs       = GridSearch(text_learner, ['mu', 'lf_w0'], [[1e-5, 1e-7],[1.0,2.0]])\n",
    "gs_stats = gs.fit(cv_candidates, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "text_learner.test_wmv(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'phen_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-240-53cad0c1c7ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpreds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlearner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpredict_wmv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphen_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0mmislabeled_cand\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgt_dict\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mphen_c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpreds\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0mgt_dic\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc2uid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mc\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mg\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmislabeled_cand\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdocument\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mname\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mg\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'phen_c' is not defined"
     ]
    }
   ],
   "source": [
    "text_preds = text_learner.predict_wmv(text_c)\n",
    "text_acronyms = [spairtxt2uid(c) for (c, p) in zip(text_c, text_preds) if p == 1]\n",
    "print text_acronyms[:10]\n",
    "mislabeled_cand = [(c,p, annotations.get(spair2uid(c), None)) for c, p in zip(text_c, text_preds) if p != annotations.get(spair2uid(c), p)]\n",
    "for (c,p,g) in mislabeled_cand[:50]:\n",
    "    _, phen, acro = spairtxt2uid(c)\n",
    "    print c.span0.context.document.name, p, g\n",
    "    print c.span0.context    \n",
    "    print c.span0.get_span(), c.span1.get_span()\n",
    "    print [LF(c) for LF in LF_txt]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# punc=','\n",
    "# for (c) in (text_c):\n",
    "#     if c.span0.context.document.name != '17903294': continue\n",
    "#     _, phen, acro = spairtxt2uid(c)\n",
    "#     print c.span0.context.document.name\n",
    "#     print c.span0.context    \n",
    "#     print c.span0.get_span(), c.span1.get_span()\n",
    "#     print [LF(c) for LF in LF_txt]\n",
    "#     print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Collect all the candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "table_preds = learner.predict_wmv(candidates)\n",
    "table_acronyms = [spair2uid(c) for (c, p) in zip(candidates, preds) if p == 1]\n",
    "print table_acronyms[:10]\n",
    "\n",
    "text_preds = text_learner.predict_wmv(text_c)\n",
    "text_acronyms = [spairtxt2uid(c) for (c, p) in zip(text_c, text_preds) if p == 1]\n",
    "print text_acronyms[:10]\n",
    "\n",
    "acronyms = table_acronyms + text_acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store relations to annotate\n",
    "with open('acronyms.extracted.tsv', 'w') as f:\n",
    "    for doc_id, str1, str2 in acronyms:\n",
    "        try:\n",
    "            out = u'{}\\t{}\\t{}\\n'.format(doc_id, unicode(str2), str1)\n",
    "            f.write(out.encode(\"UTF-8\"))\n",
    "        except:\n",
    "            print 'ERROR:', str1, str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
