{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype acronym extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This module looks at both tables and text to identify acronyms used to refer to phenotypes. These acronyms are then used to further expand SNP/phenotype relations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by configuring Jupyter and setting up our environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "import numpy as np\n",
    "import sqlalchemy\n",
    "\n",
    "# set the paths to snorkel and gwasdb\n",
    "sys.path.append('../snorkel-tables')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up the directory with the input papers\n",
    "abstract_dir = '../data/db/papers'\n",
    "\n",
    "# set up matplotlib\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)\n",
    "\n",
    "# create a Snorkel session\n",
    "from snorkel import SnorkelSession\n",
    "session = SnorkelSession()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We load our usual corpus of GWAS papers."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tables corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Part of the acronyms are found in tables. We parse these like in the other table-based modules."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLMultiDocParser\n",
    "\n",
    "xml_parser = XMLMultiDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded corpus of 589 documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import CorpusParser, OmniParser\n",
    "from snorkel.models import Corpus\n",
    "\n",
    "# parses tables into rows, cols, cells...\n",
    "table_parser = OmniParser(timeout=1000000)\n",
    "\n",
    "try:\n",
    "    table_corpus = session.query(Corpus).filter(Corpus.name == 'GWAS Table Corpus').one()\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser)\n",
    "    %time table_corpus = cp.parse_corpus(name='GWAS Table Corpus', session=session)\n",
    "    session.add(table_corpus)\n",
    "    session.commit()\n",
    "\n",
    "print 'Loaded corpus of %d documents' % len(table_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text copus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We also seek mentions of acronyms in the paper text.\n",
    "\n",
    "The following parser extracts sentences from each paper abstract, title, and the first 5 paragraphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/kuleshov/work/gwasdb/snorkel-tables/snorkel/parser.py:227: RuntimeWarning: CoreNLP skipped a malformed sentence.\n",
      "  warnings.warn(\"CoreNLP skipped a malformed sentence.\", RuntimeWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 50.7 s, sys: 2.16 s, total: 52.8 s\n",
      "Wall time: 9min 37s\n",
      "Loaded corpus of 589 documents\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import SentenceParser\n",
    "from snorkel.parser import CorpusParser\n",
    "from snorkel.models import Corpus\n",
    "\n",
    "from extractor.parser import UnicodeXMLDocParser, GWASXMLDocParser\n",
    "\n",
    "xml_parser = GWASXMLDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    title='.//front//article-title//text()',\n",
    "    abstract='.//abstract//p//text()',\n",
    "    n_par=5,\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)\n",
    "\n",
    "sent_parser = SentenceParser()\n",
    "\n",
    "try:\n",
    "    text_corpus = session.query(Corpus).filter(Corpus.name == 'GWAS Text Corpus').one()\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, sent_parser)\n",
    "    %time text_corpus = cp.parse_corpus(name='GWAS Text Corpus', session=session)\n",
    "    session.add(text_corpus)\n",
    "    session.commit()\n",
    "\n",
    "print 'Loaded corpus of %d documents' % len(text_corpus)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we generate candidates from both tables and text."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### From phenotype / acronym tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Many papers have tables with an acronym column and a phenotype column. In this section, we extract candidates from these tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define matchers for cells whose header contains a word that is indicative of a phenotype or an acronym."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# create a Snorkel class for the relation we will extract\n",
    "from snorkel.models import candidate_subclass\n",
    "AcroPhenRel = candidate_subclass('AcroPhenRel', ['acro','phen'])\n",
    "\n",
    "# Define a candidate space\n",
    "from snorkel.candidates import TableCells\n",
    "cells = TableCells()\n",
    "\n",
    "# Create a list of possible words that could denote phenotypes\n",
    "acro_words = ['abbreviation', 'acronym', 'phenotype']\n",
    "phen_words = ['trait', 'phenotype', 'description']\n",
    "\n",
    "# Define matchers\n",
    "from snorkel.matchers import CellNameDictionaryMatcher\n",
    "phen_matcher = CellNameDictionaryMatcher(axis='col', d=phen_words, n_max=3, ignore_case=True)\n",
    "acro_matcher = CellNameDictionaryMatcher(axis='col', d=acro_words, n_max=3, ignore_case=True)\n",
    "\n",
    "# we will be looking only at aligned cells\n",
    "from snorkel.throttlers import AlignmentThrottler\n",
    "row_align_filter = AlignmentThrottler(axis='row', infer=True)\n",
    "\n",
    "# create the candidate extractor\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce1 = CandidateExtractor(AcroPhenRel, [cells, cells], [acro_matcher, phen_matcher], throttler=row_align_filter)\n",
    "\n",
    "# collect that cells that will be searched for candidates\n",
    "tables = [table for doc in table_corpus.documents for table in doc.tables]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now ready to perform relation extraction."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Library/Python/2.7/site-packages/bs4/__init__.py:181: UserWarning: No parser was explicitly specified, so I'm using the best available HTML parser for this system (\"lxml\"). This usually isn't a problem, but if you run this code on another system, or in a different virtual environment, it may use a different parser and behave differently.\n",
      "\n",
      "The code that caused this warning is on line 162 of the file /System/Library/Frameworks/Python.framework/Versions/2.7/lib/python2.7/runpy.py. To get rid of this warning, change code that looks like this:\n",
      "\n",
      " BeautifulSoup([your markup])\n",
      "\n",
      "to this:\n",
      "\n",
      " BeautifulSoup([your markup], \"lxml\")\n",
      "\n",
      "  markup_type=markup_type))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[===========                             ] 27%"
     ]
    }
   ],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    tab_rels = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Tables Set').one()\n",
    "except:\n",
    "    %time tab_rels = ce1.extract(tables, 'AcroPhenRel Tables Set', session)\n",
    "    \n",
    "print \"%s relations extracted, e.g.\" % len(tab_rels)\n",
    "for cand in tab_rels[:10]:\n",
    "    print cand"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import AlignedTableRelationExtractor\n",
    "relation_extractor = AlignedTableRelationExtractor(acro_extractor, phen_extractor, axis='row', induced=True)\n",
    "tables = corpus.get_tables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 29min 20s, sys: 18.9 s, total: 29min 39s\n",
      "Wall time: 30min 8s\n",
      "267 relations extracted, e.g.\n",
      "SpanPair(Span(\"Candidate gene\", context=None, chars=[0,13], words=[0,1]), Span(\"PHENOTYPE\", context=None, chars=[0,8], words=[0,0]))\n",
      "SpanPair(Span(\"PHENOTYPE\", context=None, chars=[0,8], words=[0,0]), Span(\"Candidate gene\", context=None, chars=[0,13], words=[0,1]))\n",
      "SpanPair(Span(\"CST3\", context=None, chars=[0,3], words=[0,0]), Span(\"CysC\", context=None, chars=[0,3], words=[0,0]))\n",
      "SpanPair(Span(\"CysC\", context=None, chars=[0,3], words=[0,0]), Span(\"CST3\", context=None, chars=[0,3], words=[0,0]))\n",
      "SpanPair(Span(\"CST3\", context=None, chars=[0,3], words=[0,0]), Span(\"CysC\", context=None, chars=[0,3], words=[0,0]))\n"
     ]
    }
   ],
   "source": [
    "%time candidates = relation_extractor.extract(tables, name='all')\n",
    "table_c = candidates\n",
    "print \"%s relations extracted, e.g.\" % len(table_c)\n",
    "for cand in table_c[:5]: \n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From table phrases"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Another way of definining acronyms is in text, e.g. as in \"Body Mass Index (BMI)\". We are now going to extract such candidates from phrases that are found in paper tables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a candidate space\n",
    "from snorkel.candidates import OmniNgrams\n",
    "ngrams3 = OmniNgrams(n_max=3)\n",
    "ngrams8 = OmniNgrams(n_max=8)\n",
    "\n",
    "# Define matchers\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "phen_matcher = RegexMatchSpan(rgx=r'.+ \\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "acro_matcher = RegexMatchSpan(rgx=r'\\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "\n",
    "# We only look at phenotype and acronym matches that overlap\n",
    "from snorkel.throttlers import OverlapThrottler, WordLengthThrottler, CombinedThrottler\n",
    "overlap_filter = OverlapThrottler()\n",
    "# length_filter = WordLengthThrottler(op='max', idx=1, lim=15)\n",
    "# ovl_len_filter = CombinedThrottler([overlap_filter, length_filter])\n",
    "\n",
    "# create the candidate extractor\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce2 = CandidateExtractor(AcroPhenRel, [ngrams3, ngrams8], [acro_matcher, phen_matcher], throttler=overlap_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us now extract these candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    txt_tab_rels = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Tables Set 2').one()\n",
    "except:\n",
    "    %time txt_tab_rels = ce2.extract(table_corpus.documents, 'AcroPhenRel Tables Set 2', session)\n",
    "    \n",
    "print \"%s relations extracted, e.g.\" % len(txt_tab_rels)\n",
    "for cand in txt_tab_rels[:10]:\n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### From text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we repeat the same extraction process for candidates that are found in text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Define a candidate space\n",
    "from snorkel.candidates import Ngrams\n",
    "ngrams3 = Ngrams(n_max=3)\n",
    "ngrams8 = Ngrams(n_max=8)\n",
    "\n",
    "# Define matchers\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "phen_matcher = RegexMatchSpan(rgx=r'.+ \\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "acro_matcher = RegexMatchSpan(rgx=r'\\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "\n",
    "# We only look at phenotype and acronym matches that overlap\n",
    "from snorkel.throttlers import OverlapThrottler, WordLengthThrottler, CombinedThrottler\n",
    "overlap_filter = OverlapThrottler()\n",
    "# length_filter = WordLengthThrottler(op='max', idx=1, lim=15)\n",
    "# ovl_len_filter = CombinedThrottler([overlap_filter, length_filter])\n",
    "\n",
    "# create the candidate extractor\n",
    "from snorkel.candidates import CandidateExtractor\n",
    "ce3 = CandidateExtractor(AcroPhenRel, [ngrams3, ngrams8], [acro_matcher, phen_matcher], throttler=overlap_filter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We extract the candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    txt_txt_rels = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Text Set').one()\n",
    "except:\n",
    "    sentences = [s for doc in corpus for s in doc.sentences]\n",
    "    %time txt_txt_rels = ce2.extract(sentences, 'AcroPhenRel Text Set', session)\n",
    "    \n",
    "print \"%s relations extracted, e.g.\" % len(txt_txt_rels)\n",
    "for cand in txt_txt_rels[:10]:\n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combining the results"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we merge all the candiates into a single set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    rels = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Canidates').one()\n",
    "except:\n",
    "    rels = CandidateSet(name='AcroPhenRel Canidates')\n",
    "    for c in rels1: rels.append(c)\n",
    "    for c in rels2: rels.append(c)\n",
    "    for c in rels3: rels.append(c)\n",
    "\n",
    "    session.add(rels)\n",
    "    session.commit()\n",
    "\n",
    "print '%d candidates in total' % len(rels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 839 ms, sys: 59 ms, total: 898 ms\n",
      "Wall time: 10.7 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import SentenceParser, CorpusParser\n",
    "from extractor.parser import UnicodeXMLDocParser, GWASXMLDocParser\n",
    "\n",
    "xml_parser = GWASXMLDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    title='.//front//article-title//text()',\n",
    "    abstract='.//abstract//p//text()',\n",
    "    n_par=5,\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)\n",
    "\n",
    "sent_parser = SentenceParser()\n",
    "cp = CorpusParser(xml_parser, sent_parser, max_docs=15)\n",
    "%time text_corpus = cp.parse_corpus(name='GWAS Text Corpus')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import Ngrams, CellSpace, TableNgrams\n",
    "from snorkel.matchers import RegexMatchSpan\n",
    "from snorkel.candidates import EntityExtractor, RelationExtractor, UnionExtractor\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams8 = Ngrams(n_max=8)\n",
    "ngrams3 = Ngrams(n_max=3)\n",
    "cells = CellSpace()\n",
    "table_ngrams3 = TableNgrams(n_max=3)\n",
    "\n",
    "# Define matchers\n",
    "phen_matcher = RegexMatchSpan(rgx=r'.+ \\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "acro_matcher = RegexMatchSpan(rgx=r'\\([a-zA-Z0-9_-]{1,10}[\\);]')\n",
    "\n",
    "# Extractors\n",
    "phen_txt_ngram_extractor = EntityExtractor(ngrams8, phen_matcher)\n",
    "phen_txt_cells_extractor = EntityExtractor(cells, phen_matcher)\n",
    "acro_txt_ngram_extractor = EntityExtractor(ngrams3, acro_matcher)\n",
    "acro_txt_cells_extractor = EntityExtractor(table_ngrams3, acro_matcher)\n",
    "\n",
    "# Filtering functions\n",
    "def overlap_filter_fn(span0, span1):\n",
    "    if hasattr(span0.context, 'cell') and hasattr(span1.context, 'cell'):\n",
    "        if span0.context.cell != span1.context.cell: return False\n",
    "    if len(span1.get_span().split()) >= 15: return False\n",
    "    start0, end0 = span0.char_start, span0.char_end\n",
    "    start1, end1 = span1.char_start, span1.char_end\n",
    "    return True if start1 <= start0 <= end0 <= end1 else False\n",
    "\n",
    "# Relation extractor\n",
    "txt_tab_ngram_extractor = RelationExtractor(acro_txt_ngram_extractor, phen_txt_ngram_extractor, filter_fn=overlap_filter_fn)\n",
    "txt_tab_cells_extractor = RelationExtractor(acro_txt_cells_extractor, phen_txt_cells_extractor, filter_fn=overlap_filter_fn)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acroynms from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3.4 s, sys: 262 ms, total: 3.67 s\n",
      "Wall time: 3.76 s\n",
      "1305 candidates extracted from text in tables\n"
     ]
    }
   ],
   "source": [
    "%time txt_tab_c = txt_tab_ngram_extractor.extract(corpus.get_phrases(), name='all')\n",
    "print len(txt_tab_c), 'candidates extracted from text in tables'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acronyms from full table cells"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5.37 s, sys: 119 ms, total: 5.49 s\n",
      "Wall time: 5.42 s\n",
      "761 candidates extracted from text in full table cells\n"
     ]
    }
   ],
   "source": [
    "%time txt_cel_c = txt_tab_cells_extractor.extract(corpus.get_tables(), name='all')\n",
    "print len(txt_cel_c), 'candidates extracted from text in full table cells'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract acroynms from abstracts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 2.05 s, sys: 31.2 ms, total: 2.09 s\n",
      "Wall time: 2.09 s\n",
      "884 candidates extracted from text in abstracts\n"
     ]
    }
   ],
   "source": [
    "%time txt_txt_c = txt_tab_ngram_extractor.extract(text_corpus.get_sentences(), name='all')\n",
    "print len(txt_txt_c), 'candidates extracted from text in abstracts'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating a gold set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It will be helpful to have a list of gold labels against which to evaluate the accuracy of our system.\n",
    "\n",
    "We are going to load here a list of candidates that we have previously labeled by hand."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "annotations = dict()\n",
    "with open('acronyms.anotated.txt') as f:\n",
    "    text = f.read()\n",
    "    for line in text.split('\\r'):\n",
    "        doc_id, str1, str2, res = line.strip().split('\\t')\n",
    "        res = 1 if int(res) == 1 else -1\n",
    "        annotations[(doc_id, str2, str1)] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The format of this file is: pmid, phenotype, acronym, label. We originally generated it from 100 random candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning the correctness of relations extracted from tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we are going to use a machine learning classifier to identify correct acronyms amond our set of candidates."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we are going to train a classifier for candidates that have been extracted from tables (that had a phenotype and an acronym column)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split data into an (unlabeled) training set (since we will use unsupervised risk estimation to train a candidate on it), and a dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    tab_train_c = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Table Training Candidates').one()\n",
    "    tab_devtest_c = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Table Dev/Test Candidates').one()\n",
    "except:\n",
    "    # delete any previous sets with that name\n",
    "    session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Table Training Candidates').delete()\n",
    "    session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Table Dev/Test Candidates').delete()\n",
    "\n",
    "    # helpers/config\n",
    "    frac_test = 0.5\n",
    "    def r2id(r):\n",
    "        doc_id = r[0].parent.document.name\n",
    "        str1, str2 = r[0].get_span(), r[1].get_span()\n",
    "        return (doc_id, str1, str2)\n",
    "\n",
    "    # initialize the new sets\n",
    "    tab_train_c = CandidateSet(name='AcroPhenRel Table Training Candidates')\n",
    "    tab_devtest_c = CandidateSet(name='AcroPhenRel Table Dev/Test Candidates')\n",
    "\n",
    "    # choose a random subset for the labeled set\n",
    "    n_test = len(tab_rels) * frac_test\n",
    "    test_idx = set(np.random.choice(len(tab_rels), size=(n_test,), replace=False))\n",
    "\n",
    "    # add to the sets\n",
    "    for i, c in enumerate(tab_rels):\n",
    "        if i in test_idx:\n",
    "            tab_devtest_c.append(c)\n",
    "        elif r2id(c) in annotations:\n",
    "            tab_devtest_c.append(c)\n",
    "        else:\n",
    "            tab_train_c.append(c)\n",
    "\n",
    "    # save the results\n",
    "    session.add(tab_train_c)\n",
    "    session.add(tab_devtest_c)\n",
    "    session.commit()\n",
    "\n",
    "print 'Initialized %d training and %d dev/testing candidates' % (len(tab_train_c), len(tab_devtest_c))\n",
    "print \"Positive labels in dev/test set: %s\" % len([c for c in tab_devtest_c if annotations.get(r2id(c),0)==1])\n",
    "print \"Negative labels in dev/test set: %s\" % len([c for c in tab_devtest_c if annotations.get(r2id(c),0)==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 210\n",
      "Gold set size: 57\n",
      "Positive labels in training set: 0\n",
      "Negative labels in training set: 0\n",
      "Positive labels in gold set: 36\n",
      "Negative labels in gold set: 21\n"
     ]
    }
   ],
   "source": [
    "def spair2uid(span_pair):\n",
    "    doc_id = span_pair.span0.context.document.name\n",
    "    str1 = span_pair.span0.get_span()\n",
    "    str2 = span_pair.span1.get_span()\n",
    "    return (doc_id, str1, str2)\n",
    "\n",
    "# Split into train and test set\n",
    "training_candidates = []\n",
    "gold_candidates     = []\n",
    "gold_labels         = []\n",
    "n_half = len(candidates)/2\n",
    "for c in candidates[:n_half]:\n",
    "    uid = spair2uid(c)\n",
    "    if uid in annotations:\n",
    "        gold_candidates.append(c)\n",
    "        gold_labels.append(annotations[uid])\n",
    "    else:\n",
    "        training_candidates.append(c)\n",
    "training_candidates.extend(candidates[n_half:])\n",
    "gold_labels = np.array(gold_labels)\n",
    "print \"Training set size: %s\" % len(training_candidates)\n",
    "print \"Gold set size: %s\" % len(gold_candidates)\n",
    "print \"Positive labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==1])\n",
    "print \"Negative labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==-1])\n",
    "print \"Positive labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==1])\n",
    "print \"Negative labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the data programming approach, we define set of labeling functions. We will learn their accuracy via unsupervised learning and use them for classifying candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def LF1_digits(m):\n",
    "    txt = m[1].get_span()\n",
    "    frac_num = len([ch for ch in txt if ch.isdigit()]) / float(len(txt))\n",
    "    return -1 if frac_num > 0.5 else +1\n",
    "def LF1_short(m):\n",
    "    txt = m[1].get_span()\n",
    "    return -1 if len(txt) < 5 else 0\n",
    "\n",
    "LF_tables = [LF1_digits, LF1_short]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the LFs's on our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_tab_train = label_manager.load(session, tab_train_c, 'AcroPhenRel Table Training LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_tab_train = label_manager.create(session, tab_train_c, 'AcroPhenRel Table Training LF Labels', f=LF_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we learn their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "tab_model = NaiveBayes()\n",
    "tab_model.train(L_tab_train, n_iter=10000, rate=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our accuracy on the dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_tab_devtest = label_manager.load(session, tab_devtest_c, 'AcroPhenRel Table Dev/Test LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_tab_devtest = label_manager.create(session, tab_devtest_c, 'AcroPhenRel Table Dev/Test LF Labels', f=LF_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "L_tab_test_gold = np.array([annotations.get(r2uid[r],0) for r in tab_devtest_c])\n",
    "tab_model.score(L_tab_devtest, L_tab_test_gold, tab_devtest_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LFs...\n",
      "Featurizing...\n",
      "========================================\n",
      "Test set size:\t28\n",
      "----------------------------------------\n",
      "Precision:\t1.0\n",
      "Recall:\t\t1.0\n",
      "F1 Score:\t1.0\n",
      "----------------------------------------\n",
      "TP: 14 | FP: 0 | TN: 14 | FN: 0\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "learner.test_wmv(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we classify the entire set of candidates. We start by applying the labelling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_tab_all = label_manager.load(session, tab_rels, 'AcroPhenRel Table LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_tab_all = label_manager.create(session, tab_rels, 'AcroPhenRel Table LF Labels', f=LF_tables)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the model to predict which ones are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = tab_model.odds(L_tab_all)\n",
    "tab_acronyms = [spair2uid(c) for (c, s) in zip(tab_rels, scores) if s > 0]\n",
    "\n",
    "print 'Identified %d acronyms predicted to be correct, e.g.' % len(tab_acronyms)\n",
    "print tab_acronyms[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the correctness of relations extracted from text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we repeat our classification procedure on relations that have been extracted from phrases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We start by creating the set of all phrase relations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.models import CandidateSet\n",
    "\n",
    "try:\n",
    "    txt_rels = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Text Canidates').one()\n",
    "except:\n",
    "    txt_rels = CandidateSet(name='AcroPhenRel Text Canidates')\n",
    "    for c in txt_tab_rels: txt_rels.append(c)\n",
    "    for c in txt_txt_rels: txt_rels.append(c)\n",
    "\n",
    "    session.add(txt_rels)\n",
    "    session.commit(txt_rels)\n",
    "\n",
    "print 'Collected %d candidates from phrases' % len(txt_rels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating training and test sets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We first split data into an (unlabeled) training set (since we will use unsupervised risk estimation to train a candidate on it), and a dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "try:\n",
    "    txt_train_c = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Phrase Training Candidates').one()\n",
    "    txt_devtest_c = session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Phrase Dev/Test Candidates').one()\n",
    "except:\n",
    "    # delete any previous sets with that name\n",
    "    session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Phrase Training Candidates').delete()\n",
    "    session.query(CandidateSet).filter(CandidateSet.name == 'AcroPhenRel Phrase Dev/Test Candidates').delete()\n",
    "\n",
    "    # helpers/config\n",
    "    frac_test = 0.5\n",
    "    def r2id(r):\n",
    "        doc_id = r[0].parent.document.name\n",
    "        str1, str2 = r[0].get_span(), r[1].get_span()\n",
    "        return (doc_id, str1, str2)\n",
    "\n",
    "    # initialize the new sets\n",
    "    txt_train_c = CandidateSet(name='AcroPhenRel Phrase Training Candidates')\n",
    "    txt_devtest_c = CandidateSet(name='AcroPhenRel Phrase Dev/Test Candidates')\n",
    "\n",
    "    # choose a random subset for the labeled set\n",
    "    n_test = len(txt_rels) * frac_test\n",
    "    test_idx = set(np.random.choice(len(txt_rels), size=(n_test,), replace=False))\n",
    "\n",
    "    # add to the sets\n",
    "    for i, c in enumerate(txt_rels):\n",
    "        if i in test_idx:\n",
    "            txt_devtest_c.append(c)\n",
    "        elif r2id(c) in annotations:\n",
    "            txt_devtest_c.append(c)\n",
    "        else:\n",
    "            txt_train_c.append(c)\n",
    "\n",
    "    # save the results\n",
    "    session.add(txt_train_c)\n",
    "    session.add(txt_devtest_c)\n",
    "    session.commit()\n",
    "\n",
    "print 'Initialized %d training and %d dev/testing candidates' % (len(txt_train_c), len(txt_devtest_c))\n",
    "print \"Positive labels in dev/test set: %s\" % len([c for c in txt_devtest_c if annotations.get(r2id(c),0)==1])\n",
    "print \"Negative labels in dev/test set: %s\" % len([c for c in txt_devtest_c if annotations.get(r2id(c),0)==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labelling functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Following the data programming approach, we define set of labeling functions. We will learn their accuracy via unsupervised learning and use them for classifying candidates."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from bs4 import BeautifulSoup as soup\n",
    "from snorkel.lf_helpers import get_left_tokens\n",
    "\n",
    "# helper fn\n",
    "def r2id(r):\n",
    "    doc_id = r[0].parent.document.name\n",
    "    str1, str2 = r[0].get_span(), r[1].get_span()\n",
    "    return (doc_id, str1, str2)\n",
    "\n",
    "# positive LFs\n",
    "def LF_acro_matches(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    words = phen.strip().split()\n",
    "    if len(acro) == len(words):\n",
    "        w_acro = ''.join([w[0] for w in words])\n",
    "        if w_acro.lower() == acro.lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_matches_with_dashes(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    words = re.split(' |-', phen)\n",
    "    if len(acro) == len(words):\n",
    "        w_acro = ''.join([w[0] for w in words])\n",
    "        if w_acro.lower() == acro.lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_first_letter(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    if not any(l.islower() for l in phen): return 0\n",
    "    words = phen.strip().split()\n",
    "    if len(acro) <= len(words):\n",
    "        if words[0].lower() == acro[0].lower():\n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_prefix(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    phen = phen.replace('-', '')\n",
    "    if phen[:2].lower() == acro[:2].lower():\n",
    "        return +1\n",
    "    return 0\n",
    "\n",
    "def LF_acro_matches_last_letters(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    words = phen.strip().split()\n",
    "#     prev_words = m.span1.pre_window(d=1) + words\n",
    "    prev_words = left_text(m[1], window=1).split() + words\n",
    "    w_prev_acro = ''.join([w[0] for w in prev_words])\n",
    "    if w_prev_acro.lower() == acro.lower(): return 0\n",
    "    for r in (1,2):\n",
    "        new_acro = acro[r:]\n",
    "        if len(new_acro) < 3: continue\n",
    "        if len(new_acro) == len(words):\n",
    "            w_acro = ''.join([w[0] for w in words])\n",
    "            if w_acro.lower() == new_acro.lower():\n",
    "                return +1\n",
    "    return 0\n",
    "\n",
    "def LF_full_cell(m):\n",
    "    \"\"\"If only phrase in cell is A B C (XYZ), then it's correct\"\"\"\n",
    "    if not hasattr(m[1].parent, 'cell'): return 0\n",
    "    cell = m[1].parent.cell\n",
    "    txt_cell = soup(cell.text).text if cell.text is not None else ''\n",
    "    txt_span = m[1].get_span()\n",
    "    return 1 if cell.text == txt_span or txt_cell == txt_span else 0\n",
    "#     return 1 if m[1].parent.cell.text == m[1].get_span() else 0\n",
    "\n",
    "def LF_start(m):\n",
    "    punc = ',.;!?()\\'\"'\n",
    "    if m[1].get_word_start() == 0 or any(c in punc for c in left_text(m[1], window=1)):\n",
    "        _, acro, phen = r2id(m)\n",
    "        if phen[0].lower() == acro[0].lower(): \n",
    "            return +1\n",
    "    return 0\n",
    "\n",
    "LF_txt_pos = [LF_acro_matches, LF_acro_matches_with_dashes, LF_acro_first_letter, LF_acro_prefix, LF_acro_matches_last_letters, LF_full_cell, LF_start]\n",
    "\n",
    "# negative LFs\n",
    "def LF_no_pos(m):\n",
    "    return -1 if not any(LF(m) for LF in LF_txt_pos) else 0\n",
    "\n",
    "def LF_short(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    return -1 if len(acro) == 1 else 0\n",
    "\n",
    "def LF_lc(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    return -1 if all(l.islower() for l in acro) else 0\n",
    "\n",
    "def LF_uc(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    return -2 if not any(l.islower() for l in phen) else 0\n",
    "\n",
    "def LF_punc(m):\n",
    "    _, acro, phen = r2id(m)\n",
    "    punc = ',.;!?()'\n",
    "    return -1 if any(c in punc for c in phen) else 0\n",
    "    \n",
    "\n",
    "LF_txt_neg = [LF_no_pos, LF_short, LF_lc, LF_uc, LF_punc]\n",
    "\n",
    "LF_txt = LF_txt_pos + LF_txt_neg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We compute the LFs on our training set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_txt_train = label_manager.load(session, txt_train_c, 'AcroPhenRel Phrase Training LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_txt_train = label_manager.create(session, txt_train_c, 'AcroPhenRel Phrase Training LF Labels', f=LF_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And we learn their accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.learning import NaiveBayes\n",
    "\n",
    "txt_model = NaiveBayes()\n",
    "txt_model.train(L_txt_train, n_iter=10000, rate=1e-2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluating the model's accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We evaluate our accuracy on the dev/test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_txt_devtest = label_manager.load(session, txt_devtest_c, 'AcroPhenRel Phrase Dev/Test LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_txt_devtest = label_manager.create(session, txt_devtest_c, 'AcroPhenRel Phrase Dev/Test LF Labels', f=LF_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "L_txt_test_gold = np.array([annotations.get(r2uid[r],0) for r in txt_devtest_c])\n",
    "txt_model.score(L_txt_devtest, L_txt_test_gold, txt_devtest_c)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LFs...\n",
      "Featurizing...\n",
      "========================================\n",
      "Test set size:\t97\n",
      "----------------------------------------\n",
      "Precision:\t0.615384615385\n",
      "Recall:\t\t1.0\n",
      "F1 Score:\t0.761904761905\n",
      "----------------------------------------\n",
      "TP: 24 | FP: 15 | TN: 58 | FN: 0\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "text_learner.test_wmv(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Candidate classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Finally, we classify the entire set of candidates. We start by applying the labelling functions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from snorkel.annotations import LabelManager\n",
    "label_manager = LabelManager()\n",
    "\n",
    "try:\n",
    "    %time L_txt_all = label_manager.load(session, txt_rels, 'AcroPhenRel Table LF Labels')\n",
    "except sqlalchemy.orm.exc.NoResultFound:\n",
    "    %time L_txt_all = label_manager.create(session, txt_rels, 'AcroPhenRel Table LF Labels', f=LF_txt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We use the model to predict which ones are correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "scores = txt_model.odds(L_txt_all)\n",
    "txt_acronyms = [r2id(c) for (c, s) in zip(txt_rels, scores) if s > 0]\n",
    "\n",
    "print 'Identified %d acronyms predicted to be correct, e.g.' % len(txt_acronyms)\n",
    "print txt_acronyms[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LFs...\n",
      "Featurizing...\n",
      "[('17903292', u'GFR', u'Glomerular Filtration Rate'), ('17903292', u'TSH', u'Thyroid stimulation hormone'), ('17903292', u'DHEAS', u'Dehydroepiandrosterone sulfate'), ('17903292', u'Mb', u'Physical Location'), ('17903292', u'Mb', u'Physical Location'), ('17903292', u'Mb', u'Physical location'), ('17903292', u'GEE', u'Mean p-value'), ('17903292', u'FBAT', u'Mean p-value'), ('17903292', u'GEE', u'P_value'), ('17903294', u'min-max', u'Sample size')]\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 3, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 189, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 383, 0, u'Physical location (Mb)')\n",
      "(Mb) Physical location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 2, 5, 0, u'Mean p-value (GEE)')\n",
      "(GEE) Mean p-value (GEE)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 2, 6, 0, u'Mean p-value (FBAT)')\n",
      "(FBAT) Mean p-value (FBAT)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 3, 7, 0, u'P_value (GEE)')\n",
      "(GEE) P_value (GEE)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903297 1.0 -1\n",
      "Phrase('17903297', 0, 93, 0, u'Similarities (Sim)')\n",
      "(Sim) Similarities (Sim)\n",
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903300 1.0 -1\n",
      "Phrase('17903300', 1, 3, 0, u'Physical Position (Mb)')\n",
      "(Mb) Physical Position (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903300 1.0 -1\n",
      "Phrase('17903300', 1, 190, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 3, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 189, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 1, 383, 0, u'Physical location (Mb)')\n",
      "(Mb) Physical location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 2, 5, 0, u'Mean p-value (GEE)')\n",
      "(GEE) Mean p-value (GEE)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 2, 6, 0, u'Mean p-value (FBAT)')\n",
      "(FBAT) Mean p-value (FBAT)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Phrase('17903292', 3, 7, 0, u'P_value (GEE)')\n",
      "(GEE) P_value (GEE)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903297 1.0 -1\n",
      "Phrase('17903297', 0, 87, 0, u'Boston Naming Test (Nam)')\n",
      "(Nam) Naming Test (Nam)\n",
      "[0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903297 1.0 -1\n",
      "Phrase('17903297', 0, 93, 0, u'Similarities (Sim)')\n",
      "(Sim) Similarities (Sim)\n",
      "[0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903298 -1.0 1\n",
      "Phrase('17903298', 0, 18, 0, u'28 yr time averaged FPG (tFPG)')\n",
      "(tFPG) time averaged FPG (tFPG)\n",
      "[0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
      "\n",
      "17903300 1.0 -1\n",
      "Phrase('17903300', 1, 3, 0, u'Physical Position (Mb)')\n",
      "(Mb) Physical Position (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903300 1.0 -1\n",
      "Phrase('17903300', 1, 190, 0, u'Physical Location (Mb)')\n",
      "(Mb) Physical Location (Mb)\n",
      "[0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903301 -1.0 1\n",
      "Phrase('17903301', 0, 50, 0, u'Stage 2 Exercise diastolic blood pressure (DBP)')\n",
      "(DBP) blood pressure (DBP)\n",
      "[0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
      "\n",
      "17903292 1.0 -1\n",
      "Sentence(Document('17903292', Corpus (GWAS Text Corpus)), 3, u'We tested for association between the Affymetrix GeneChip Human Mapping 100K single nucleotide polymorphism (SNP) set and measures of kidney function and endocrine traits.')\n",
      "(SNP) single nucleotide polymorphism (SNP)\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903294 -1.0 1\n",
      "Sentence(Document('17903294', Corpus (GWAS Text Corpus)), 1, u'Increased circulating levels of hemostatic factors as well as anemia have been associated with increased risk of cardiovascular disease (CVD).')\n",
      "(CVD) cardiovascular disease (CVD)\n",
      "[0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
      "\n",
      "17903294 1.0 -1\n",
      "Sentence(Document('17903294', Corpus (GWAS Text Corpus)), 3, u'We sought to confirm known putative loci and identify novel loci that may influence either trait in genome-wide association and linkage analyses using the Affymetrix GeneChip 100K single nucleotide polymorphism (SNP) set.')\n",
      "(SNP) single nucleotide polymorphism (SNP)\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903294 -1.0 1\n",
      "Sentence(Document('17903294', Corpus (GWAS Text Corpus)), 14, u'Elevated circulating levels of hemostatic factors, such as fibrinogen [1-3], plasminogen activator inhibitor (PAI-1) [4,5], von Willebrand factor (vWF) [6], tissue plasminogen activator (tPA) [4,5,7], factor VII (FVII) [8], and D-dimer [9,10] are linked to the development of atherothrombosis and are risk markers for coronary heart disease (CHD), stroke and other cardiovascular disease (CVD) events.')\n",
      "(CVD) cardiovascular disease (CVD)\n",
      "[0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
      "\n",
      "17903294 1.0 -1\n",
      "Sentence(Document('17903294', Corpus (GWAS Text Corpus)), 21, u'The recent completion of a genome-wide scan using the Affymetrix GeneChip Human Mapping 100K single nucleotide polymorphism (SNP) set on participants in the Framingham Heart Study offered the opportunity to conduct a genome-wide association study (GWAS) and linkage scan for variants that influence hemostatic factors and hematological phenotypes.')\n",
      "(SNP) single nucleotide polymorphism (SNP)\n",
      "[1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903300 -1.0 1\n",
      "Sentence(Document('17903300', Corpus (GWAS Text Corpus)), 1, u'Obesity is related to multiple cardiovascular disease (CVD) risk factors as well as CVD and has a strong familial component.')\n",
      "(CVD) cardiovascular disease (CVD)\n",
      "[0, 0, 0, 0, 0, 0, 0, -1, 0, 0, 0, 0]\n",
      "\n",
      "17903301 1.0 -1\n",
      "Sentence(Document('17903301', Corpus (GWAS Text Corpus)), 7, u'Generalized estimating equations (GEE), family-based association tests (FBAT) and variance-components linkage were used to relate multivariable-adjusted trait residuals to 70,987 SNPs (Human 100K GeneChip, Affymetrix) restricted to autosomal SNPs with minor allele frequency \\u22650.10, genotype call rate \\u22650.80, and Hardy-Weinberg equilibrium p \\u2265 0.001.')\n",
      "(GEE) Generalized estimating equations (GEE)\n",
      "[1, 1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\n",
      "17903304 1.0 -1\n",
      "Sentence(Document('17903304', Corpus (GWAS Text Corpus)), 2, u'In many industrialized countries, cardiovascular disease (CVD) claims more lives each year than any other disease.')\n",
      "(CVD) cardiovascular disease (CVD)\n",
      "[0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "text_preds = text_learner.predict_wmv(text_c)\n",
    "text_acronyms = [spairtxt2uid(c) for (c, p) in zip(text_c, text_preds) if p == 1]\n",
    "print text_acronyms[:10]\n",
    "mislabeled_cand = [(c,p, annotations.get(spair2uid(c), None)) for c, p in zip(text_c, text_preds) if p != annotations.get(spair2uid(c), p)]\n",
    "# for (c,p,g) in mislabeled_cand[:50]:\n",
    "#     _, phen, acro = spairtxt2uid(c)\n",
    "#     print c.span0.context.document.name, p, g\n",
    "#     print c.span0.context    \n",
    "#     print c.span0.get_span(), c.span1.get_span()\n",
    "#     print [LF(c) for LF in LF_txt]\n",
    "#     print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# punc=','\n",
    "# for (c) in (text_c):\n",
    "#     if c.span0.context.document.name != '17903294': continue\n",
    "#     _, phen, acro = spairtxt2uid(c)\n",
    "#     print c.span0.context.document.name\n",
    "#     print c.span0.context    \n",
    "#     print c.span0.get_span(), c.span1.get_span()\n",
    "#     print [LF(c) for LF in LF_txt]\n",
    "#     print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Store the predicted candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "693"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(acronyms)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "acronyms = tab_acronyms + txt_acronyms\n",
    "print '%d acronyms resolved' % len(acronyms)\n",
    "\n",
    "# store relations to annotate\n",
    "with open('acronyms.extracted.all.tsv', 'w') as f:\n",
    "    for doc_id, str1, str2 in acronyms:\n",
    "        try:\n",
    "            out = u'{}\\t{}\\t{}\\n'.format(doc_id, unicode(str2), str1)\n",
    "            f.write(out.encode(\"UTF-8\"))\n",
    "        except:\n",
    "            print 'ERROR:', str1, str2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
