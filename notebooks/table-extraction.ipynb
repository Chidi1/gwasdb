{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SNP/Phenotype detection from raw text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import numpy as np\n",
    "import cPickle, os, sys\n",
    "np.random.seed(seed=1701)\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (18,6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# import snorkel and gwasdb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Assemble a corpus"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Collect all the tables in our dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLDocParser\n",
    "from extractor.parser import UnicodeXMLTableDocParser\n",
    "\n",
    "xml_parser = UnicodeXMLTableDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 16min 35s, sys: 49.8 s, total: 17min 25s\n",
      "Wall time: 24min 36s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "from extractor.parser import UnicodeTableParser\n",
    "from snorkel.parser import CorpusParser\n",
    "import cPickle\n",
    "\n",
    "table_parser = UnicodeTableParser()\n",
    "html_parser = HTMLParser(path='../data/db/papers/')\n",
    "\n",
    "corpus_name = 'gwas-table-corpus.pkl'\n",
    "\n",
    "try:\n",
    "    with open(corpus_name,\"r\") as pkl:\n",
    "        corpus = cPickle.load(pkl)\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser)\n",
    "    %time corpus = cp.parse_corpus(name='GWAS Corpus')\n",
    "    # pickling currently doesn't work...\n",
    "#     with open(corpus_name,\"w\") as pkl:\n",
    "#         corpus = cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# pickling currently doesn't work...\n",
    "# import cPickle\n",
    "# with open(corpus_name,\"w\") as pkl:\n",
    "#     corpus = cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Try extracting rs-ids first"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# add new paths\n",
    "sys.path.append('../src/crawler')\n",
    "sys.path.append('../src/crawler/db')\n",
    "\n",
    "# import new libs\n",
    "from kb import KnowledgeBase\n",
    "from extractor.util import gold_rsid_stats, gold_rsid_precision\n",
    "\n",
    "from snorkel.candidates import Ngrams\n",
    "from snorkel.matchers import DictionaryMatch, RegexMatchSpan, Union\n",
    "from snorkel.candidates import EntityExtractor\n",
    "\n",
    "# from snorkel.candidates import Candidates"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create a gold set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a list of all the rs-ids we know."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "kb = KnowledgeBase()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Get a gold set:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_set = frozenset( [ (doc.name, rs_id) for doc in corpus.documents for rs_id in kb.rsids_by_pmid(int(doc.name)) ] )\n",
    "gold_set_rsids = [rs_id for doc_id, rs_id in gold_set]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_rsid_dict = {doc_id : set() for doc_id, rs_id in gold_set}\n",
    "for docid, rsid in gold_set:\n",
    "    gold_rsid_dict[docid].add(rsid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10073\n"
     ]
    }
   ],
   "source": [
    "print len(gold_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=1)\n",
    "\n",
    "# Define matchers\n",
    "gold_rsid_matcher = DictionaryMatch(d=gold_set_rsids, longest_match_only=False)\n",
    "regx_rsid_matcher = RegexMatchSpan(rgx=r'rs\\d+(/[^s]+)?')\n",
    "# dict_rsid_matcher = DictionaryMatch(d=rs_ids, longest_match_only=False)\n",
    "# rsid_matcher = Union(dict_rsid_matcher, regx_rsid_matcher)\n",
    "\n",
    "rsid_extractor = EntityExtractor(ngrams, regx_rsid_matcher)\n",
    "# %time rs_candidates = rsid_extractor.extract(corpus.get_tables(), name='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1992662\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1992660\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1793004\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs10521209\", context=None, chars=[0,9], words=[0,0])\n",
      "Span(\"rs2631372\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs2925757\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs6947579\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs1553575\", context=None, chars=[0,8], words=[0,0])\n",
      "Span(\"rs10484545\", context=None, chars=[0,9], words=[0,0])\n",
      "15330 candidates extracted\n",
      "Phrase('17684544', 1, 20, 0, u'rs2076756')\n",
      "Cell('17684544', 1, 20, u'rs2076756')\n",
      "rs10490924/T 1\n",
      "rs10737680/A 1\n",
      "rs429608/G 1\n",
      "rs2230199/C 1\n",
      "rs5749482/G 1\n",
      "rs4420638/A 1\n",
      "rs1864163/G 1\n",
      "rs943080/T 1\n",
      "rs13278062/T 1\n",
      "rs920915/C 1\n",
      "rs4698775/G 1\n",
      "rs3812111/T 1\n",
      "rs13081855/T 1\n",
      "rs3130783/A 1\n",
      "rs8135665/T 1\n",
      "rs334353/T 1\n",
      "rs8017304/A 1\n",
      "rs6795735/T 1\n",
      "rs9542236/C 1\n"
     ]
    }
   ],
   "source": [
    "for cand in rs_candidates[:10]: \n",
    "    print cand\n",
    "print \"%s candidates extracted\" % len(rs_candidates)\n",
    "print rs_candidates[0].context\n",
    "print rs_candidates[0].context.cell\n",
    "\n",
    "for cand in rs_candidates:\n",
    "    if cand.context.document.name == '23455636':\n",
    "        print cand.get_span(), cand.context.table.position"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Statistics on all the rsid candidates:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of gold annotations\t= 10537\n",
      "# of candidates\t\t= 12005\n",
      "Candidate recall\t= 0.427\n",
      "Candidate precision\t= 0.375\n"
     ]
    }
   ],
   "source": [
    "gold_rsid_stats(rs_candidates, gold_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting: some SNPs seem to be never mentioned (e.g. rs12122100) while others (rs727153) appear only in the text.\n",
    "\n",
    "Sometimes, it's not picked up for a different, strange reason: see rs13314993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('24945404', 'rs13204965')\n",
      "('24386095', 'rs10158897')\n",
      "('23251661', 'rs10514310')\n",
      "('23382691', 'rs10822136')\n",
      "('20686565', 'rs6065906')\n",
      "('20395239', 'rs10483727')\n",
      "('23251661', 'rs9997524')\n",
      "('20858683', 'rs853789')\n",
      "('22005930', 'rs9811423')\n",
      "('22589738', 'rs1498095')\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_rsid_recall\n",
    "\n",
    "incorrect_rsids = list(gold_rsid_recall(rs_candidates, gold_set))\n",
    "for ngram in incorrect_rsids[:10]:\n",
    "    print ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Phrase('17903294', 6, 127, 0, u'rs10514919')\n",
      "Phrase('17903294', 6, 136, 0, u'rs10514919')\n",
      "Phrase('17903294', 6, 145, 0, u'rs2015729')\n",
      "Phrase('17903294', 6, 154, 0, u'rs2015729')\n",
      "Phrase('17903294', 6, 163, 0, u'rs2015729')\n",
      "Phrase('17903294', 6, 199, 0, u'rs6956010')\n",
      "Phrase('17903294', 6, 208, 0, u'rs6956010')\n",
      "Phrase('17903294', 6, 217, 0, u'rs6956010')\n",
      "Phrase('17903294', 6, 226, 0, u'rs917858')\n",
      "Phrase('17903294', 6, 235, 0, u'rs917859')\n",
      "Phrase('17903294', 6, 244, 0, u'rs2239138')\n",
      "Phrase('17903294', 6, 253, 0, u'rs216901')\n",
      "Phrase('17903294', 6, 262, 0, u'rs216903')\n",
      "Phrase('17903294', 6, 271, 0, u'rs216904')\n",
      "Phrase('17903294', 7, 29, 0, u'rs7741731')\n",
      "Phrase('17903294', 7, 77, 0, u'rs4075265')\n",
      "Phrase('17903294', 7, 89, 0, u'rs915171')\n",
      "Phrase('17903294', 7, 113, 0, u'rs6938586')\n",
      "Phrase('17903294', 7, 125, 0, u'rs3777442')\n",
      "Phrase('17903294', 7, 185, 0, u'rs2105250')\n",
      "Phrase('17903294', 7, 197, 0, u'rs9321263')\n",
      "Phrase('17903294', 7, 209, 0, u'rs1811949')\n",
      "Phrase('17903294', 7, 221, 0, u'rs9321265')\n",
      "Phrase('17903294', 7, 233, 0, u'rs7761311')\n",
      "Phrase('17903294', 7, 281, 0, u'rs4128714')\n",
      "Phrase('17903294', 7, 293, 0, u'rs2105819')\n",
      "Phrase('17903294', 7, 341, 0, u'rs3898916')\n",
      "Phrase('17903294', 7, 353, 0, u'rs10499199')\n",
      "Phrase('17903294', 7, 365, 0, u'rs10499200')\n",
      "Phrase('17903294', 7, 377, 0, u'rs10499201')\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_rsid_precision\n",
    "\n",
    "strange_ngrams = list(gold_rsid_precision(rs_candidates, gold_set))\n",
    "for ngram in strange_ngrams[70:100]:\n",
    "    print ngram.context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store candidates that occur in sufficiently large tables:\n",
    "rsid_by_table = dict()\n",
    "for cand in rs_candidates:\n",
    "    rsid = cand.get_span()\n",
    "    key = cand.context.document.name, cand.context.table.position\n",
    "    if key not in rsid_by_table: rsid_by_table[key] = set()\n",
    "    rsid_by_table[key].add((rsid, cand.context.cell.row_num, cand.context.cell.col_num))\n",
    "    \n",
    "with open('rsids.singletons.all.tsv', 'w') as f:\n",
    "    for (pmid, table_id), rsids in rsid_by_table.items():\n",
    "        if len(rsids) < 10: continue\n",
    "        for rsid, row_num, col_num in rsids:\n",
    "            f.write('%s\\t%s\\t%s\\t%s\\t%s\\n' % (pmid, table_id, row_num, col_num, rsid))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "set([u'rs6577648', u'rs254315', u'rs10520880', u'rs38276', u'rs986831', u'rs10520246', u'rs7610584', u'rs3751832', u'rs3794889', u'rs10492797', u'rs9327886', u'rs10505624', u'rs208354', u'rs4418248', u'rs10514443', u'rs10486031', u'rs10513681', u'rs216666', u'rs10515347', u'rs10487577', u'rs2253319', u'rs7989050', u'rs4801149', u'rs10512920', u'rs3017183', u'rs2371438', u'rs6555491', u'rs10520247', u'rs10256504', u'rs7329659', u'rs392715', u'rs2834645', u'rs10497958', u'rs1261256', u'rs6102912', u'rs4782742'])\n"
     ]
    }
   ],
   "source": [
    "print rsid_by_table[('17903305', 4)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Get candidate p-values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to use regular expressions for this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 3min 7s, sys: 18.9 s, total: 3min 26s\n",
      "Wall time: 4min 34s\n"
     ]
    }
   ],
   "source": [
    "from extractor.matcher import PvalMatcher\n",
    "from snorkel.candidates import EntityExtractor, TableNgrams\n",
    "from snorkel.matchers import RegexMatchSpan, Union\n",
    "\n",
    "# 1: p-value matcher\n",
    "\n",
    "rgx1 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[\\xd7\\*][\\s\\u2009]*10[\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher1 = RegexMatchSpan(rgx=rgx1)\n",
    "rgx2 = u'[1-9]\\d?[\\xb7\\.]?\\d*[\\s\\u2009]*[eE][\\s\\u2009]*[-\\u2212\\u2013\\u2012][\\s\\u2009]*\\d+'\n",
    "pval_rgx_matcher2 = RegexMatchSpan(rgx=rgx2)\n",
    "rgx3 = u'0\\.0000+\\d+'\n",
    "pval_rgx_matcher3 = RegexMatchSpan(rgx=rgx3)\n",
    "pval_rgx_matcher = Union(pval_rgx_matcher1, pval_rgx_matcher2, pval_rgx_matcher3)\n",
    "# pval_matcher = PvalMatcher()\n",
    "ngrams = TableNgrams(n_max=7)\n",
    "pval_rgx_extractor = EntityExtractor(ngrams, pval_rgx_matcher)\n",
    "# %time pval_c = pval_extractor.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "# 2: column-based matcher\n",
    "\n",
    "from snorkel.candidates import CellSpace\n",
    "from snorkel.matchers import CellNameRegexMatcher\n",
    "\n",
    "cells = CellSpace()\n",
    "pval_rgx = 'p\\s?.?\\s?value'\n",
    "pval_rgxname_matcher = CellNameRegexMatcher(axis='col', rgx=pval_rgx, n_max=3, ignore_case=True, header_only=True, max_chars=20)\n",
    "pval_rgxname_extractor = EntityExtractor(cells, pval_rgxname_matcher)\n",
    "\n",
    "# %time pval_regex_candidates = pval_rgxname_extractor.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "# 3: combine the two\n",
    "\n",
    "from snorkel.candidates import UnionExtractor\n",
    "pval_extractor = UnionExtractor([pval_rgx_extractor, pval_rgxname_extractor])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 28\n",
      "2 8 1.44 E − 06 3 8 6.08 E − 06 4 8 1.09 E − 05 5 8 1.11 E − 05 6 8 2.61 E − 05\n"
     ]
    }
   ],
   "source": [
    "special_doc = [doc for doc in corpus.documents if doc.name == '23509613'][0]\n",
    "special_table = special_doc.tables[4]\n",
    "\n",
    "pval_regex_candidates = pval_rgx_extractor.extract([special_table])\n",
    "# pval_regex_canidates = pval_rgxname_extractor.extract(corpus.get_tables())\n",
    "print len(pval_regex_candidates)\n",
    "for c in pval_regex_candidates[:5]:\n",
    "    print c.context.cell.row_num, c.context.cell.col_num, c.get_span(), #c.context.cell.head_cell('col').text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pval_c' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-33-b98890ea37ca>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mngrams\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTableNgrams\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mn_max\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m7\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mprint\u001b[0m \u001b[0;34m'Got %d candidates, e.g.:'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpval_c\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mcandidate\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mpval_c\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0municode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcandidate\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'pval_c' is not defined"
     ]
    }
   ],
   "source": [
    "ngrams = TableNgrams(n_max=7)\n",
    "\n",
    "print 'Got %d candidates, e.g.:' % len(pval_c)\n",
    "for candidate in pval_c[:10]:\n",
    "    print unicode(candidate)\n",
    "    print candidate.context\n",
    "#     for t in ngrams.apply(candidate.context):\n",
    "#         print unicode(t.get_span())\n",
    "#         print re.match(rgx, t.get_span())\n",
    "#     print [unicode(t.get_span()) for t in ngrams.apply(candidate.context)]\n",
    "#     print\n",
    "#     print candidate.get_attrib_span('words')\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Filter nested p-value estimates e.g. 1.2\\*10^-7 and 2*10^-7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1246 1246\n"
     ]
    }
   ],
   "source": [
    "# load existing candidates into a dict\n",
    "span_dict = { str(span.context.cell) : list() for span in pval_c }\n",
    "for span in pval_c:\n",
    "    span_dict[str(span.context.cell)].append( (span.char_start, span.char_end) )\n",
    "\n",
    "def nested(ivl1, ivl2):\n",
    "    if ivl1 != ivl2 and ivl2[0] <= ivl1[0] <= ivl1[1] <= ivl2[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "new_pval_c = list()\n",
    "for span in pval_c:\n",
    "    span_ivl = span.char_start, span.char_end\n",
    "    span_name = str(span.context.cell)\n",
    "    if all([not nested(span_ivl, other_ivl) for other_ivl in span_dict[span_name]]):\n",
    "        new_pval_c.append(span)\n",
    "#     else:\n",
    "#         print span_ivl, span_dict[span_name]\n",
    "#         print unicode(span)\n",
    "#         print unicode(span.context.cell.text)\n",
    "#         print span.uid\n",
    "#         print span.context.row_num, span.context.col_num\n",
    "#         print unicode(span)\n",
    "#         print\n",
    "#         print [(cell, cell.row_num, cell.col_num) for cell in span.context.table.cells]\n",
    "#         break\n",
    "\n",
    "print len(new_pval_c), len(pval_c)\n",
    "pval_c = new_pval_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, how many p-values that should be present do we extract?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6.2e-05\n",
      "1.85e-20\n"
     ]
    }
   ],
   "source": [
    "# we need to define a p-value -> float converter\n",
    "from extractor.util import pvalue_to_float, gold_pval_stats, gold_pval_precision\n",
    "\n",
    "print pvalue_to_float(u\"6.2×10 −5\")\n",
    "print pvalue_to_float(u\"1.85×10 −20\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from kb import KnowledgeBase\n",
    "kb = KnowledgeBase()\n",
    "gold_set_pvals = frozenset([ (doc.name, pval) for doc in corpus.documents for pval in kb.pvals_by_pmid(int(doc.name)) ])\n",
    "gold_set_dict = {doc.name: kb.assoc_by_pmid(int(doc.name)) for doc in corpus.documents }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will be looking at precision/recall over p-values that are known to be associated with a SNP, and the rsid of that SNP occurs somewhere in the document (as determined above)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 107 gold mentions, e.g.:\n",
      "[('17903300', 1e-07), ('17903300', 2e-07), ('17903294', 2e-06), ('17903296', 2e-07), ('17903303', 4.9999999999999996e-06)]\n",
      "\n",
      "p-value candidate extraction statistics:\n",
      "[('17684544', 1e-21), ('17684544', 4e-07), ('17684544', 3e-06), ('17903292', 9.000000000000001e-09), ('17903292', 2e-06), ('17903292', 4e-06), ('17903292', 7e-06), ('17903292', 8e-06), ('17903293', 1e-14), ('17903293', 4e-12)]\n",
      "[('17684544', -21.0), ('17684544', -7.0), ('17684544', -6.0), ('17903292', -9.0), ('17903292', -6.0), ('17903293', -14.0), ('17903293', -12.0), ('17903293', -8.0), ('17903293', -7.0), ('17903293', -6.0)]\n",
      "[('17684544', -49.0), ('17684544', -41.0), ('17684544', -34.0), ('17684544', -28.0), ('17684544', -22.0), ('17684544', -21.0), ('17684544', -20.0), ('17684544', -18.0), ('17684544', -17.0), ('17684544', -14.0)]\n",
      "# of gold annotations\t= 35\n",
      "# of candidates\t\t= 78\n",
      "Candidate recall\t= 0.886\n",
      "Candidate precision\t= 0.397\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_pval_stats, gold_pval_stats_limited\n",
    "\n",
    "print 'Found %d gold mentions, e.g.:' % len(gold_set_pvals)\n",
    "print list(gold_set_pvals)[:5]\n",
    "print\n",
    "\n",
    "print 'p-value candidate extraction statistics:'\n",
    "# print gold_pval_stats(pval_c, gold_set_pvals, gold_set_dict)\n",
    "print gold_pval_stats_limited(pval_c, gold_set_dict, rs_candidates)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Some debugging... We will print the papers and their pvalues that are not found in the paper. Below, is the list of all SNPs associated with the paper, so we can find the SNP that is missing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extractor.util import gold_pval_recall, gold_pval_precision\n",
    "missing = list(gold_pval_recall(pval_c, gold_set_dict, rs_candidates))\n",
    "# print gold_pval_precision(pval_c, gold_set_pvals)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17903298 -8.0\n",
      "[(2e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (3e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (2e-08, u'Fasting plasma glucose', -8.0, u'rs2722425'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs10510634'), (7e-07, u'Diabetes (incident)', -7.0, u'rs10497721'), (8e-06, u'Diabetes related insulin traits', -6.0, u'rs10486607'), (9e-06, u'Diabetes related insulin traits', -6.0, u'rs2066219'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (6e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (9e-06, u'Fasting plasma glucose', -6.0, u'rs2722425'), (7e-06, u'Fasting plasma glucose', -6.0, u'rs7731657')]\n",
      "\n",
      "17903302 -9.0\n",
      "[(2e-06, u'Blood pressure', -6.0, u'rs10493340'), (3e-06, u'Blood pressure', -6.0, u'rs1963982'), (3e-06, u'Blood pressure', -6.0, u'rs935334'), (2e-06, u'Tonometry', -6.0, u'rs6063312'), (3e-06, u'Tonometry', -6.0, u'rs770189'), (6e-06, u'Tonometry', -6.0, u'rs10514688'), (6e-06, u'Tonometry', -6.0, u'rs7042864'), (8e-06, u'Tonometry', -6.0, u'rs1322512'), (2e-07, u'Tonometry', -7.0, u'rs3773643'), (2e-06, u'Tonometry', -6.0, u'rs3793427'), (2e-06, u'Tonometry', -6.0, u'rs6492654'), (3e-06, u'Tonometry', -6.0, u'rs1367248'), (4e-06, u'Tonometry', -6.0, u'rs10521232'), (4e-06, u'Tonometry', -6.0, u'rs3766680'), (4e-06, u'Tonometry', -6.0, u'rs1371924'), (8e-06, u'Tonometry', -6.0, u'rs10488172'), (4e-06, u'Blood pressure', -6.0, u'rs4370013'), (4e-06, u'Blood pressure', -6.0, u'rs10491334'), (4.9999999999999996e-06, u'Blood pressure', -6.0, u'rs2121070'), (7e-06, u'Blood pressure', -6.0, u'rs2509458'), (3e-07, u'Blood pressure', -7.0, u'rs7591163'), (1e-09, u'Blood pressure', -9.0, u'rs3096277')]\n",
      "\n",
      "17903298 -6.0\n",
      "[(2e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (3e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (2e-08, u'Fasting plasma glucose', -8.0, u'rs2722425'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs10510634'), (7e-07, u'Diabetes (incident)', -7.0, u'rs10497721'), (8e-06, u'Diabetes related insulin traits', -6.0, u'rs10486607'), (9e-06, u'Diabetes related insulin traits', -6.0, u'rs2066219'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (6e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (9e-06, u'Fasting plasma glucose', -6.0, u'rs2722425'), (7e-06, u'Fasting plasma glucose', -6.0, u'rs7731657')]\n",
      "\n",
      "17903298 -7.0\n",
      "[(2e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (3e-06, u'Diabetes related insulin traits', -6.0, u'rs2877832'), (2e-08, u'Fasting plasma glucose', -8.0, u'rs2722425'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs10510634'), (7e-07, u'Diabetes (incident)', -7.0, u'rs10497721'), (8e-06, u'Diabetes related insulin traits', -6.0, u'rs10486607'), (9e-06, u'Diabetes related insulin traits', -6.0, u'rs2066219'), (4.9999999999999996e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (6e-06, u'Fasting plasma glucose', -6.0, u'rs180730'), (9e-06, u'Fasting plasma glucose', -6.0, u'rs2722425'), (7e-06, u'Fasting plasma glucose', -6.0, u'rs7731657')]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from math import log10, floor\n",
    "\n",
    "for pmid, pval in missing[:5]:\n",
    "    print pmid, pval\n",
    "    print [(a.pvalue, a.phenotype.name, floor(log10(a.pvalue)), a.snp.rs_id) for a in gold_set_dict[pmid]]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The SNPs above are either labeled incorrectly (most of the time), or could also not occur in tables."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extract candidate relations between SNPs and p-values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import AlignedTableRelationExtractor\n",
    "# Relation Extractor:\n",
    "relation_extractor = AlignedTableRelationExtractor(rsid_extractor, pval_rgx_extractor, axis='row')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 13s, sys: 7min 49s, total: 16min 3s\n",
      "Wall time: 49min 45s\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"1.93E-13\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"2.04E-12\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"6.80E-20\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"1.39E-21\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"5.90E-08\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs1992662\", context=None, chars=[0,8], words=[0,0]), Span(\"7.59E-05\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs1992660\", context=None, chars=[0,8], words=[0,0]), Span(\"4.53E-05\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs10521209\", context=None, chars=[0,9], words=[0,0]), Span(\"8.65E-05\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs10521209\", context=None, chars=[0,9], words=[0,0]), Span(\"8.68E-05\", context=None, chars=[0,7], words=[0,0]))\n",
      "SpanPair(Span(\"rs1553575\", context=None, chars=[0,8], words=[0,0]), Span(\"1.68E-06\", context=None, chars=[0,7], words=[0,0]))\n",
      "22077 relations extracted\n"
     ]
    }
   ],
   "source": [
    "%time candidates = relation_extractor.extract(corpus.get_tables(), name='all')\n",
    "\n",
    "for cand in candidates[:10]: \n",
    "    print cand\n",
    "print \"%s relations extracted\" % len(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "63\n",
      "63\n"
     ]
    }
   ],
   "source": [
    "print candidates[1000].span0.context.cell.row_num\n",
    "print candidates[1000].span1.context.cell.row_num"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's consider the subset of gold SNPs that have been found to match somewhere with a table."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[u'rs9932186', u'rs6880595', u'rs12989701', u'rs6606686', u'rs12470505']\n"
     ]
    }
   ],
   "source": [
    "rs_subset = set([span_pair.span0.get_span().lower() for span_pair in candidates])\n",
    "print list(rs_subset)[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(u'rs1883025', 3e-27), (u'rs10811661', 7e-07), (u'rs1532085', 7e-47), (u'rs174546', 6e-07), (u'rs163879', 2e-11)]\n",
      "5304\n"
     ]
    }
   ],
   "source": [
    "gold_relations = set([(assoc.snp.rs_id, assoc.pvalue) for doc in corpus.documents for assoc in kb.assoc_by_pmid(doc.name) if assoc.snp.rs_id.lower() in rs_subset])\n",
    "print list(gold_relations)[:5]\n",
    "print len(gold_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2e-24"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "kb.assoc_by_pmid(18483556)[10].pvalue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# of gold annotations\t= 4853\n",
      "# of candidates\t\t= 16645\n",
      "Candidate recall\t= 0.792\n",
      "Candidate precision\t= 0.231\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_rspval_stats\n",
    "\n",
    "gold_rspval_stats(candidates, gold_relations)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Why low precision?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"1.93E-13\", context=None, chars=[0,7], words=[0,0]))\n",
      "Table('17684544', 1) 2 1\n",
      "\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"2.04E-12\", context=None, chars=[0,7], words=[0,0]))\n",
      "Table('17684544', 1) 2 1\n",
      "\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"6.80E-20\", context=None, chars=[0,7], words=[0,0]))\n",
      "Table('17684544', 1) 2 1\n",
      "\n",
      "SpanPair(Span(\"rs2076756\", context=None, chars=[0,8], words=[0,0]), Span(\"5.90E-08\", context=None, chars=[0,7], words=[0,0]))\n",
      "Table('17684544', 1) 2 1\n",
      "\n",
      "SpanPair(Span(\"rs1992662\", context=None, chars=[0,8], words=[0,0]), Span(\"7.59E-05\", context=None, chars=[0,7], words=[0,0]))\n",
      "Table('17684544', 1) 3 1\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from extractor.util import gold_rspval_precision\n",
    "\n",
    "strange_rels = gold_rspval_precision(candidates, gold_relations)\n",
    "for rel in strange_rels[:5]:\n",
    "    print rel\n",
    "    print rel.span0.context.table, rel.span0.context.cell.row_num, rel.span0.context.cell.col_num\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It seems like there are many pvalues for the same span and only one of them is actually correct."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Save this for now"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "from extractor.util import pvalue_to_float\n",
    "\n",
    "def clean_rsid(rsid):\n",
    "    return re.sub('/.+', '', rsid)\n",
    "\n",
    "with open('pval-rsid.raw.cols.tsv', 'w') as f:\n",
    "    for rel in candidates:\n",
    "        pmid = rel.span0.context.document.name\n",
    "        table_id = rel.span0.context.table.position\n",
    "        row_id = rel.span0.context.cell.row_num\n",
    "        col_id = rel.span0.context.cell.col_num\n",
    "        rsid = rel.span0.get_span()\n",
    "        pval = pvalue_to_float(rel.span1.get_span())\n",
    "\n",
    "        out_str = '%s\\t%s\\t%d\\t%d\\t%d\\t%f\\n' % (pmid, clean_rsid(rsid), table_id, row_id, col_id, pval)\n",
    "        f.write(out_str)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Store tables that have pvalue columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import re\n",
    "pval_rgx = 'p\\s?.?\\s?value'\n",
    "lod_rgx = 'LOD'\n",
    "\n",
    "with open('table-annotations.tsv', 'w') as f:\n",
    "    for doc in corpus.documents:\n",
    "        for table in doc.tables:\n",
    "            lod_found = 0\n",
    "            pval_found = 0\n",
    "            for cell in table.cells:\n",
    "                if not pval_found and len(cell.text) < 30 and re.search(pval_rgx, cell.text, re.IGNORECASE):\n",
    "                    pval_found = 1\n",
    "                if not lod_found and re.search(lod_rgx, cell.text):\n",
    "                    lod_found = 1\n",
    "                if pval_found and lod_found: break\n",
    "                    \n",
    "            out_str = '%s\\t%s\\t%s\\t%s\\n' % (doc.name, table.position, pval_found, lod_found)\n",
    "            f.write(out_str) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Learning the rsid/pvalue relation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the gold set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extractor.util import get_exponent, pvalue_to_float\n",
    "\n",
    "gold_relations = set([(assoc.snp.rs_id, assoc.pvalue) for doc in corpus.documents for assoc in kb.assoc_by_pmid(doc.name) if assoc.snp.rs_id.lower() in rs_subset])\n",
    "gold_relations = set([ (rs_id, get_exponent(pval)) for rs_id, pval in gold_relations ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4614 16280\n"
     ]
    }
   ],
   "source": [
    "def spair2uid(span_pair):\n",
    "    doc_id = span_pair.span0.context.document.name\n",
    "    table_id = str(span_pair.span0.context.table.position)\n",
    "    str1 = span_pair.span0.get_span()\n",
    "    str2 = span_pair.span1.get_span()\n",
    "    return (doc_id, table_id, str1, str2)\n",
    "\n",
    "gt_dict_pos = dict()\n",
    "gt_dict_neg = dict()\n",
    "for crel in candidates:\n",
    "    uid = spair2uid(crel)\n",
    "    if (crel.span0.get_span(), get_exponent(pvalue_to_float(crel.span1.get_span()))) in gold_relations:\n",
    "        gt_dict_pos[uid] = +1\n",
    "    else:\n",
    "        gt_dict_neg[uid] = -1\n",
    "\n",
    "print len(gt_dict_pos), len(gt_dict_neg)\n",
    "gt_dict = dict(gt_dict_pos.items() + gt_dict_neg.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20894"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(gt_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load the features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Extract features, and store them to a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature index...\n"
     ]
    }
   ],
   "source": [
    "from snorkel.features import TableNgramPairFeaturizer\n",
    "\n",
    "# pkl_f = 'phenotype_feats.pkl'\n",
    "# try:\n",
    "#     with open(pkl_f, 'rb') as f:\n",
    "#         featurizer = cPickle.load(f)\n",
    "# except:\n",
    "featurizer = TableNgramPairFeaturizer()\n",
    "featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for f in featurizer.get_features_by_candidate(candidates[0])[:10]: print f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pkl_f = 'rsid_pval_feats.pkl'\n",
    "with open(pkl_f, 'w+') as f:\n",
    "    cPickle.dump(featurizer, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split into training and test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Split into train and test set\n",
    "training_candidates = []\n",
    "gold_candidates     = []\n",
    "gold_labels         = []\n",
    "n_half = len(candidates)/2\n",
    "for c in candidates[:n_half]:\n",
    "    uid = spair2uid(c)\n",
    "    if uid in gt_dict:\n",
    "        gold_candidates.append(c)\n",
    "        gold_labels.append(gt_dict[uid])\n",
    "    else:\n",
    "        training_candidates.append(c)\n",
    "training_candidates.extend(candidates[n_half:])\n",
    "gold_labels = np.array(gold_labels)\n",
    "print \"Training set size: %s\" % len(training_candidates)\n",
    "print \"Gold set size: %s\" % len(gold_candidates)\n",
    "print \"Positive labels in training set: %s\" % len([c for c in training_candidates if gt_dict.get(spair2uid(c),0)==1])\n",
    "print \"Negative labels in training set: %s\" % len([c for c in training_candidates if gt_dict.get(spair2uid(c),0)==-1])\n",
    "print \"Positive labels in gold set: %s\" % len([c for c in gold_candidates if gt_dict[spair2uid(c)]==1])\n",
    "print \"Negative labels in gold set: %s\" % len([c for c in gold_candidates if gt_dict[spair2uid(c)]==-1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeling functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rsid_keywords = [\"id\", \"rsid\", \"snp\"]\n",
    "pval_keywords = [\"value\", \"p-value\", \"p-val\", \"p_value\", \"pvalue\"]\n",
    "\n",
    "# positive LFs\n",
    "def LF_pval_header(m):\n",
    "    # if \"pvalue\" is mentioned in first or last row, it's probably correct\n",
    "    pass\n",
    "def LF_pval_aligned(m):\n",
    "    # if \"pvalue\" is mentioned in aligned cells, it's probably correct\n",
    "    return +1 if any(kw in m.span1.aligned_ngrams('words') for kw in pval_keywords) else 0\n",
    "def LF_id_aligned(m):\n",
    "    # if \"id\" is mentioned in aligned cells, it's probably correct    \n",
    "    return +1 if any(kw in m.span0.aligned_ngrams('words') for kw in rsid_keywords) else 0\n",
    "def LF_phen_aligned(m):\n",
    "    # if there is an aligned phenotype, then it is probably correct\n",
    "    pass\n",
    "\n",
    "# negative LFs\n",
    "def LF_align(m):\n",
    "    # if the two spans don't align in the table, then they're clearly wrong    \n",
    "    return -1 if m.span0.context.row_num != m.span1.context.row_num and \\\n",
    "                 m.span0.context.col_num != m.span1.context.col_num \\\n",
    "              else 0\n",
    "def LF_diff_col(m):\n",
    "    return -1 if m.span0.context.col_num != m.span1.context.col_num else 0\n",
    "\n",
    "pos_LFs = [LF_pval_aligned, LF_id_aligned]\n",
    "neg_LFs = [LF_align]\n",
    "LFs = pos_LFs + neg_LFs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "__init__() got an unexpected keyword argument 'featurizer'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-50-1ef5a53c5b64>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0msnorkel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfeatures\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mNgramFeaturizer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mtraining_set\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTrainingSet\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtraining_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLFs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfeaturizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mTableNgramPairFeaturizer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m: __init__() got an unexpected keyword argument 'featurizer'"
     ]
    }
   ],
   "source": [
    "from snorkel.snorkel import TrainingSet\n",
    "from snorkel.features import NgramFeaturizer\n",
    "\n",
    "training_set = TrainingSet(training_candidates, LFs, featurizer=TableNgramPairFeaturizer())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lf_stats = training_set.lf_stats()\n",
    "lf_stats[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "lf_stats.hist(\"coverage\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.snorkel import Learner\n",
    "import snorkel.learning\n",
    "from snorkel.learning import LogReg\n",
    "print snorkel.learning.__dict__\n",
    "\n",
    "learner = Learner(training_set, model=snorkel.learning.LogRegSKLearn())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Splitting into CV and test set\n",
    "n_half = len(gold_candidates)/2\n",
    "test_candidates = gold_candidates[:n_half]\n",
    "test_labels     = gold_labels[:n_half]\n",
    "cv_candidates   = gold_candidates[n_half:]\n",
    "cv_labels       = gold_labels[n_half:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.learning_utils import GridSearch\n",
    "\n",
    "gs       = GridSearch(learner, ['mu', 'lf_w0'], [[1e-5, 1e-7],[1.0,2.0]])\n",
    "gs_stats = gs.fit(cv_candidates, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gs_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner.test(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner.feature_stats(n_max=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "mislabeled_cand = learner.mislabeled_test_candidates(test_candidates, test_labels)\n",
    "for (c,p,g) in mislabeled_cand[50:500]:\n",
    "    snp_name = c.span0.get_span()\n",
    "    if snp_name not in gold_rel_dict: continue\n",
    "    print c.span0.context.document.name\n",
    "    print c.span0.context    \n",
    "    print c.span1.context\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_rel_dict = dict(gold_relations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "gold_rel_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
