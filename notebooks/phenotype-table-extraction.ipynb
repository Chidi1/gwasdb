{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Phenotype/SNP relation extraction from tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "import cPickle\n",
    "\n",
    "# import snorkel and gwasdb\n",
    "sys.path.append('../snorkel')\n",
    "sys.path.append('../src')\n",
    "sys.path.append('../src/crawler')\n",
    "\n",
    "# set up paths\n",
    "abstract_dir = '../data/db/papers'\n",
    "\n",
    "# set up matplotlib\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "%matplotlib inline\n",
    "matplotlib.rcParams['figure.figsize'] = (12,4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.parser import XMLDocParser\n",
    "from extractor.parser import UnicodeXMLTableDocParser\n",
    "\n",
    "xml_parser = UnicodeXMLTableDocParser(\n",
    "    path=abstract_dir,\n",
    "    doc='./*',\n",
    "    text='.//table',\n",
    "    id='.//article-id[@pub-id-type=\"pmid\"]/text()',\n",
    "    keep_xml_tree=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 56.3 s, sys: 3.34 s, total: 59.6 s\n",
      "Wall time: 1min 35s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.parser import HTMLParser\n",
    "from extractor.parser import UnicodeTableParser\n",
    "from snorkel.parser import CorpusParser\n",
    "import cPickle\n",
    "\n",
    "table_parser = UnicodeTableParser()\n",
    "html_parser = HTMLParser(path='../data/db/papers/')\n",
    "\n",
    "corpus_name = 'gwas-table-corpus.pkl'\n",
    "\n",
    "try:\n",
    "    with open(corpus_name,\"r\") as pkl:\n",
    "        corpus = cPickle.load(pkl)\n",
    "except:\n",
    "    cp = CorpusParser(xml_parser, table_parser, max_docs=15)\n",
    "    %time corpus = cp.parse_corpus(name='GWAS Corpus')\n",
    "    # pickling currently doesn't work...\n",
    "#     with open(corpus_name,\"w\") as pkl:\n",
    "#         corpus = cPickle.dump(corpus, pkl)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Candidate extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RSid Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.matchers import DictionaryMatch, RegexMatchSpan, Union\n",
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams\n",
    "\n",
    "from db.kb import KnowledgeBase\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=1)\n",
    "\n",
    "# Get a list of all the RSids we know\n",
    "kb = KnowledgeBase()\n",
    "rs_ids = kb.get_rsid_candidates()\n",
    "\n",
    "# Define matchers\n",
    "dict_rsid_matcher = DictionaryMatch(d=rs_ids, longest_match_only=False)\n",
    "regx_rsid_matcher = RegexMatchSpan(rgx=r'rs\\d+')\n",
    "rsid_matcher = Union(dict_rsid_matcher, regx_rsid_matcher)\n",
    "\n",
    "rsid_extractor = EntityExtractor(ngrams, rsid_matcher)\n",
    "# %time rs_candidates = rsid_extractor.extract(corpus.get_tables(), name='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'rs_candidates' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-23-a3e733b1f7df>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mfor\u001b[0m \u001b[0mcand\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrs_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0;32mprint\u001b[0m \u001b[0mcand\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0;34m\"%s candidates extracted\"\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrs_candidates\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrs_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;32mprint\u001b[0m \u001b[0mrs_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcontext\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcell\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'rs_candidates' is not defined"
     ]
    }
   ],
   "source": [
    "# for cand in rs_candidates[:10]: \n",
    "#     print cand\n",
    "# print \"%s candidates extracted\" % len(rs_candidates)\n",
    "# print rs_candidates[0].context\n",
    "# print rs_candidates[0].context.cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extractor.util import gold_rsid_stats, gold_rsid_precision\n",
    "\n",
    "gold_set = frozenset( [ (doc.name, rs_id) for doc in corpus.documents for rs_id in kb.rsids_by_pmid(int(doc.name)) ] )\n",
    "gold_set_rsids = [rs_id for doc_id, rs_id in gold_set]\n",
    "\n",
    "gold_rsid_stats(rs_candidates, gold_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interesting: some SNPs seem to be never mentioned (e.g. rs12122100) while others (rs727153) appear only in the text.\n",
    "Sometimes, it's not picked up for a different, strange reason: see rs13314993."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cells = rs_candidates[0].context.cell.aligned_cells('row')\n",
    "[cell.text for cell in cells]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Phenotypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 22 s, sys: 295 ms, total: 22.3 s\n",
      "Wall time: 22.8 s\n"
     ]
    }
   ],
   "source": [
    "from snorkel.matchers import DictionaryMatch, Union, CellNameMatcher, CellDictNameMatcher\n",
    "from snorkel.candidates import EntityExtractor\n",
    "from snorkel.candidates import TableNgrams, CellSpace\n",
    "\n",
    "# Define a candidate space\n",
    "ngrams = TableNgrams(n_max=9)\n",
    "cells = CellSpace()\n",
    "\n",
    "# Create a list of possible words that could denote phenotypes\n",
    "phen_words = ['trait', 'phenotype']\n",
    "\n",
    "# Define matchers\n",
    "# dict_row_matcher = DictionaryMatch(d=phen_words, longest_match_only=False, stemmer='porter')\n",
    "# cell_row_matcher = CellNameMatcher(row_matcher=dict_row_matcher, cand_space=ngrams)\n",
    "# dict_col_matcher = DictionaryMatch(d=phen_words, longest_match_only=False, stemmer='porter')\n",
    "# cell_col_matcher = CellNameMatcher(col_matcher=dict_col_matcher, cand_space=ngrams)\n",
    "# phen_matcher = Union(cell_row_matcher, cell_col_matcher)\n",
    "# phen_matcher = CellNameMatcher(col_matcher=dict_col_matcher, cand_space=ngrams)\n",
    "phen_matcher = CellDictNameMatcher(axis='col', d=phen_words, n_max=3, ignore_case=True)\n",
    "\n",
    "phen_extractor = EntityExtractor(cells, phen_matcher)\n",
    "%time phen_candidates = phen_extractor.extract(corpus.get_tables(), name='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1851 candidates extracted\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 10, u'Serum Creatinine')\n",
      "Span(\"Serum Creatinine\", context=None, chars=[0,15], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 15, u'Change in serum creatinine')\n",
      "Span(\"Change in serum creatinine\", context=None, chars=[0,25], words=[0,3])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 20, u'Glomerular Filtration Rate (GFR)')\n",
      "Span(\"Glomerular Filtration Rate (GFR)\", context=None, chars=[0,35], words=[0,5])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 25, u'Chronic Kidney Disease')\n",
      "Span(\"Chronic Kidney Disease\", context=None, chars=[0,21], words=[0,2])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 30, u'Cystatin C')\n",
      "Span(\"Cystatin C\", context=None, chars=[0,9], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 35, u'Uric acid')\n",
      "Span(\"Uric acid\", context=None, chars=[0,8], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 40, u'Urinary Albumin Excretion')\n",
      "Span(\"Urinary Albumin Excretion\", context=None, chars=[0,24], words=[0,2])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 45, u'Urinary Albumin Excretion \\u2265 30 mg/g; Hypertension-enriched sample')\n",
      "Span(\"Urinary Albumin Excretion ≥ 30 mg/g; Hypertension-enriched sample\", context=None, chars=[0,64], words=[0,8])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 50, u'Serum Calcium')\n",
      "Span(\"Serum Calcium\", context=None, chars=[0,12], words=[0,1])\n",
      "17903292 Table('17903292', 0) Cell('17903292', 0, 55, u'Serum Phosphorus')\n",
      "Span(\"Serum Phosphorus\", context=None, chars=[0,15], words=[0,1])\n",
      "\n",
      "Phrase('17903292', 0, 10, 0, u'Serum Creatinine')\n",
      "17903292 Table('17903292', 0)\n",
      "Cell('17903292', 0, 10, u'Serum Creatinine')\n"
     ]
    }
   ],
   "source": [
    "print \"%s candidates extracted\" % len(phen_candidates)\n",
    "for cand in phen_candidates[0:10]: \n",
    "    print cand.context.document.name, cand.context.table, cand.context.cell\n",
    "    print unicode(cand)\n",
    "#     print [span for span in cand.row_ngrams()]\n",
    "#     print [span for span in cand.col_ngrams()]\n",
    "#     print\n",
    "print\n",
    "print phen_candidates[0].context\n",
    "print phen_candidates[0].context.document.name, phen_candidates[0].context.table\n",
    "print phen_candidates[0].context.cell"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from snorkel.candidates import AlignedTableRelationExtractor\n",
    "relation_extractor = AlignedTableRelationExtractor(rsid_extractor, phen_extractor, axis='row', induced=True)\n",
    "tables = corpus.get_tables()\n",
    "\n",
    "# create smaller subsets for evaluation/debugging\n",
    "easy_tables = [tables[8]]\n",
    "# hard_tables = [t for t in tables if t.document.name=='17658951']\n",
    "hard_doc = [d for d in corpus.documents if d.name == '17903293'][0]\n",
    "hard_tables = [hard_doc.tables[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1578 relations extracted, e.g.\n",
      "SpanPair(Span(\"rs1158167\", context=None, chars=[0,8], words=[0,0]), Span(\"CysC\", context=None, chars=[0,3], words=[0,0]))\n",
      "SpanPair(Span(\"rs1712790\", context=None, chars=[0,8], words=[0,0]), Span(\"UAE\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs6977660\", context=None, chars=[0,8], words=[0,0]), Span(\"TSH\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs9322817\", context=None, chars=[0,8], words=[0,0]), Span(\"TSH\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs10499559\", context=None, chars=[0,9], words=[0,0]), Span(\"TSH\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs9305354\", context=None, chars=[0,8], words=[0,0]), Span(\"UAE\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs2145231\", context=None, chars=[0,8], words=[0,0]), Span(\"CysC\", context=None, chars=[0,3], words=[0,0]))\n",
      "SpanPair(Span(\"rs723464\", context=None, chars=[0,7], words=[0,0]), Span(\"UAE\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs2113379\", context=None, chars=[0,8], words=[0,0]), Span(\"UAE\", context=None, chars=[0,2], words=[0,0]))\n",
      "SpanPair(Span(\"rs2839235\", context=None, chars=[0,8], words=[0,0]), Span(\"GFR\", context=None, chars=[0,2], words=[0,0]))\n"
     ]
    }
   ],
   "source": [
    "%time candidates = relation_extractor.extract(tables, name='all')\n",
    "print \"%s relations extracted, e.g.\" % len(candidates)\n",
    "for cand in candidates[:10]: \n",
    "    print cand"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here, we remove nested candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 candidates dropped, now we have 1578\n"
     ]
    }
   ],
   "source": [
    "# load existing candidates into a dict\n",
    "span_dict = { str(span_pair.span1.context) : list() for span_pair in candidates }\n",
    "for span_pair in candidates:\n",
    "    span = span_pair.span1\n",
    "    span_dict[str(span.context)].append( (span.char_start, span.char_end) )\n",
    "\n",
    "def nested(ivl1, ivl2):\n",
    "    if ivl1 != ivl2 and ivl2[0] <= ivl1[0] <= ivl1[1] <= ivl2[1]:\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "new_candidates = list()\n",
    "for span_pair in candidates:\n",
    "    span = span_pair.span1\n",
    "    span_ivl = span.char_start, span.char_end\n",
    "    span_name = str(span.context)\n",
    "    if all([not nested(span_ivl, other_ivl) for other_ivl in span_dict[span_name]]):\n",
    "        new_candidates.append(span_pair)\n",
    "        \n",
    "print len(candidates) - len(new_candidates), 'candidates dropped, now we have', len(new_candidates)\n",
    "# phen_c = new_phen_c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Learning the correctness of relations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating a gold set"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To create a gold set, we save all extracted relations into a csv file. We annotate it manually, and save the result to a second file. It contains pairs of phenotype and rsid strings; if that file exists, we take these as gold truth."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# store relations to annotate\n",
    "with open('rels.acroynms.unnanotated.tsv', 'w') as f:\n",
    "    for span_pair in new_candidates:\n",
    "        doc_id = span_pair.span0.context.document.name\n",
    "        table_id = span_pair.span0.context.table.position\n",
    "        row_num = span_pair.span0.context.cell.row_num\n",
    "        str1 = span_pair.span0.get_span()\n",
    "        str2 = span_pair.span1.get_span()\n",
    "        try:\n",
    "            f.write('%s\\t%s\\t%d\\t%s\\t%s\\n' % (doc_id, table_id, row_num, str1, str2))\n",
    "        except:\n",
    "            continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# load annotations\n",
    "annotations = dict()\n",
    "with open('rels.acronyms.annotated.txt') as f:\n",
    "    text = f.read()\n",
    "    for line in text.split('\\r'):\n",
    "        doc_id, table_id, col_n, rs_id, phen, res = line.strip().split('\\t')\n",
    "        res = 1 if int(res) == 1 else -1\n",
    "        annotations[(doc_id, table_id, rs_id, phen)] = res"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "### Classify correct relations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building feature index...\n",
      "Extracting features...\n",
      "0/22341\n",
      "5000/22341\n",
      "10000/22341\n",
      "15000/22341\n",
      "20000/22341\n"
     ]
    }
   ],
   "source": [
    "from snorkel.features import TableNgramPairFeaturizer\n",
    "\n",
    "pkl_f = 'acro_table_feats.pkl'\n",
    "try:\n",
    "    with open(pkl_f, 'rb') as f:\n",
    "        featurizer = cPickle.load(f)\n",
    "except:\n",
    "    featurizer = TableNgramPairFeaturizer()\n",
    "    featurizer.fit_transform(candidates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training set size: 884\n",
      "Gold set size: 694\n",
      "Positive labels in training set: 789\n",
      "Negative labels in training set: 0\n",
      "Positive labels in gold set: 555\n",
      "Negative labels in gold set: 139\n"
     ]
    }
   ],
   "source": [
    "def spair2uid(span_pair):\n",
    "    doc_id = span_pair.span0.context.document.name\n",
    "    table_id = str(span_pair.span0.context.table.position)\n",
    "    str1 = span_pair.span0.get_span()\n",
    "    str2 = span_pair.span1.get_span()\n",
    "    return (doc_id, table_id, str1, str2)\n",
    "\n",
    "# Split into train and test set\n",
    "training_candidates = []\n",
    "gold_candidates     = []\n",
    "gold_labels         = []\n",
    "n_half = len(candidates)/2\n",
    "for c in candidates[:n_half]:\n",
    "    uid = spair2uid(c)\n",
    "    if uid in annotations:\n",
    "        gold_candidates.append(c)\n",
    "        gold_labels.append(annotations[uid])\n",
    "    else:\n",
    "        training_candidates.append(c)\n",
    "training_candidates.extend(candidates[n_half:])\n",
    "gold_labels = np.array(gold_labels)\n",
    "print \"Training set size: %s\" % len(training_candidates)\n",
    "print \"Gold set size: %s\" % len(gold_candidates)\n",
    "print \"Positive labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==1])\n",
    "print \"Negative labels in training set: %s\" % len([c for c in training_candidates if annotations.get(spair2uid(c),0)==-1])\n",
    "print \"Positive labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==1])\n",
    "print \"Negative labels in gold set: %s\" % len([c for c in gold_candidates if annotations[spair2uid(c)]==-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# negative LFs\n",
    "def LF_number(m):\n",
    "    txt = m.span1.get_span()\n",
    "    frac_num = len([ch for ch in txt if ch.isdigit()]) / float(len(txt))\n",
    "    return -1 if frac_num > 0.6 else 0\n",
    "\n",
    "def LF_bad_phen_mentions(m):\n",
    "    top_cells = m.span1.context.cell.aligned_cells(axis='col', induced=True)\n",
    "    top_phrases = [phrase for cell in top_cells for phrase in cell.phrases]\n",
    "    if not top_phrases: return 0\n",
    "    matching_phrases = []\n",
    "    for phrase in top_phrases:\n",
    "        if any (phen_matcher._f_span(word) for word in phrase.text.split(' ')):\n",
    "            matching_phrases.append(phrase)\n",
    "    small_matching_phrases = [phrase for phrase in matching_phrases if len(phrase.text) <= 25]\n",
    "    return -1 if not small_matching_phrases else 0\n",
    "\n",
    "LF_tables_neg = [LF_number, LF_bad_phen_mentions]\n",
    "\n",
    "# positive LFs\n",
    "def LF_no_neg(m):\n",
    "    return +1 if not any(LF(m) for LF in LF_tables_neg) else 0\n",
    "\n",
    "LF_tables_pos = [LF_no_neg]\n",
    "\n",
    "LF_tables = LF_tables_neg + LF_tables_pos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Applying LFs...\n",
      "Featurizing...\n",
      "Building feature index...\n",
      "Extracting features...\n",
      "0/14220\n",
      "5000/14220\n",
      "10000/14220\n",
      "============================================================\n",
      "LF Summary Statistics: 3 LFs applied to 884 candidates\n",
      "------------------------------------------------------------\n",
      "Coverage (candidates w/ > 0 labels):\t\t100.00%\n",
      "Overlap (candidates w/ > 1 labels):\t\t0.00%\n",
      "Conflict (candidates w/ conflicting labels):\t0.00%\n",
      "============================================================\n"
     ]
    }
   ],
   "source": [
    "from snorkel.snorkel import TrainingSet\n",
    "from snorkel.features import NgramFeaturizer\n",
    "\n",
    "training_set = TrainingSet(training_candidates, LF_tables, featurizer=TableNgramPairFeaturizer())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "============================================================\n",
      "Testing mu = 1.00e-05, lf_w0 = 1.00e+00\n",
      "============================================================\n",
      "Begin training for rate=0.01, mu=1e-05\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027207\n",
      "\tLearning epoch = 250\tGradient mag. = 0.047458\n",
      "\tLearning epoch = 500\tGradient mag. = 0.076673\n",
      "\tLearning epoch = 750\tGradient mag. = 0.119269\n",
      "Final gradient magnitude for rate=0.01, mu=1e-05: 0.180\n",
      "Applying LFs...\n",
      "Featurizing...\n",
      "============================================================\n",
      "Testing mu = 1.00e-05, lf_w0 = 2.00e+00\n",
      "============================================================\n",
      "Begin training for rate=0.01, mu=1e-05\n",
      "\tLearning epoch = 0\tGradient mag. = 0.052007\n",
      "\tLearning epoch = 250\tGradient mag. = 0.082656\n",
      "\tLearning epoch = 500\tGradient mag. = 0.117942\n",
      "\tLearning epoch = 750\tGradient mag. = 0.163135\n",
      "Final gradient magnitude for rate=0.01, mu=1e-05: 0.210\n",
      "============================================================\n",
      "Testing mu = 1.00e-07, lf_w0 = 1.00e+00\n",
      "============================================================\n",
      "Begin training for rate=0.01, mu=1e-07\n",
      "\tLearning epoch = 0\tGradient mag. = 0.027207\n",
      "\tLearning epoch = 250\tGradient mag. = 0.047555\n",
      "\tLearning epoch = 500\tGradient mag. = 0.076892\n",
      "\tLearning epoch = 750\tGradient mag. = 0.119632\n",
      "Final gradient magnitude for rate=0.01, mu=1e-07: 0.180\n",
      "============================================================\n",
      "Testing mu = 1.00e-07, lf_w0 = 2.00e+00\n",
      "============================================================\n",
      "Begin training for rate=0.01, mu=1e-07\n",
      "\tLearning epoch = 0\tGradient mag. = 0.052007\n"
     ]
    }
   ],
   "source": [
    "from snorkel.snorkel import Learner\n",
    "import snorkel.learning\n",
    "from snorkel.learning import LogReg\n",
    "\n",
    "learner = Learner(training_set, model=LogReg())\n",
    "\n",
    "# Splitting into CV and test set\n",
    "n_half = len(gold_candidates)/2\n",
    "test_candidates = gold_candidates[:n_half]\n",
    "test_labels     = gold_labels[:n_half]\n",
    "cv_candidates   = gold_candidates[n_half:]\n",
    "cv_labels       = gold_labels[n_half:]\n",
    "\n",
    "from snorkel.learning_utils import GridSearch\n",
    "gs       = GridSearch(learner, ['mu', 'lf_w0'], [[1e-5, 1e-7],[1.0,2.0]])\n",
    "gs_stats = gs.fit(cv_candidates, cv_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learner.test_wmv(test_candidates, test_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# preds = learner.predict_wmv(candidates)\n",
    "acronyms = [spair2uid(c) for (c, p) in zip(candidates, preds) if p == 1]\n",
    "mislabeled_cand = [(c,p, annotations.get(spair2uid(c), None)) for c, p in zip(candidates, preds) if p != annotations.get(spair2uid(c), p)]\n",
    "for (c,p,g) in mislabeled_cand[:20]:\n",
    "    print c.span0.context.document.name, p, g\n",
    "    print c.span0.context    \n",
    "    print c.span0.get_span(), c.span1.get_span()\n",
    "    txt = c.span1.get_span()\n",
    "    top_cells = c.span1.context.cell.aligned_cells(axis='col', induced=True)\n",
    "    top_phrases = [phrase for cell in top_cells for phrase in cell.phrases]\n",
    "    print top_phrases\n",
    "    matching_phrases = []\n",
    "    for phrase in top_phrases:\n",
    "        print [(word,phen_matcher._f_span(word)) for word in phrase.text.split(' ')]\n",
    "        if any (phen_matcher._f_span(word) for word in phrase.text.split(' ')):\n",
    "            matching_phrases.append(phrase)\n",
    "            print phrase\n",
    "#         print phrase, [phen_matcher._f_span(word) for word in phrase.text.split(' ')]\n",
    "    print [LF(c) for LF in LF_tables]\n",
    "    print"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print phen_matcher._stem('Phenotype*')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "preds = learner.predict_wmv(candidates)\n",
    "rels = [(c.span0.context.document.name, c.span0.get_span(), c.span1.get_span()) for (c, p) in zip(candidates, preds) if p == 1]\n",
    "print len(rels), 'relations extracted, e.g.:'\n",
    "print rels[:10]\n",
    "\n",
    "# store relations to annotate\n",
    "with open('rels.acronyms.extracted.tsv', 'w') as f:\n",
    "    for doc_id, str1, str2 in rels:\n",
    "        try:\n",
    "            out = u'{}\\t{}\\t{}\\n'.format(doc_id, unicode(str1), str2)\n",
    "            f.write(out.encode(\"UTF-8\"))\n",
    "        except:\n",
    "            print 'Error in saving:', str1, str2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Resolve acronyms based on ones extracted earlier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from extractor.dictionary import Dictionary, unravel\n",
    "\n",
    "D = Dictionary()\n",
    "D.load('acronyms.extracted.tsv')\n",
    "print len(D), 'definitions loaded'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use dictionary to resolve acronyms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "new_rels = [ (doc_id, rs_id, unravel(doc_id, phen, D)) for doc_id, rs_id, phen in rels ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for rel in new_rels[:1000]:\n",
    "    print rel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print D.storage['17903292']\n",
    "print D.evidence['17903292']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unravel('17903292', u'CysC', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
